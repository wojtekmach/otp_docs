searchNodes=[{"doc":"The module cover provides a set of functions for coverage analysis of Erlang programs, counting how many times each executable line of code is executed when a program is run. An executable line contains an Erlang expression such as a matching or a function call. A blank line or a line containing a comment, function head or pattern in a case - or receive statement is not executable. Coverage analysis can be used to verify test cases, making sure all relevant code is covered, and may also be helpful when looking for bottlenecks in the code. Before any analysis can take place, the involved modules must be Cover compiled . This means that some extra information is added to the module before it is compiled into a binary which then is loaded. The source file of the module is not affected and no .beam file is created. Each time a function in a Cover compiled module is called, information about the call is added to an internal database of Cover. The coverage analysis is performed by examining the contents of the Cover database. The output Answer is determined by two parameters, Level and Analysis . Level = module Answer = {Module,Value} , where Module is the module name. Level = function Answer = [{Function,Value}] , one tuple for each function in the module. A function is specified by its module name M , function name F and arity A as a tuple {M,F,A} . Level = clause Answer = [{Clause,Value}] , one tuple for each clause in the module. A clause is specified by its module name M , function name F , arity A and position in the function definition C as a tuple {M,F,A,C} . Level = line Answer = [{Line,Value}] , one tuple for each executable line in the module. A line is specified by its module name M and line number in the source file N as a tuple {M,N} . Analysis = coverage Value = {Cov,NotCov} where Cov is the number of executable lines in the module, function, clause or line that have been executed at least once and NotCov is the number of executable lines that have not been executed. Analysis = calls Value = Calls which is the number of times the module, function, or clause has been called. In the case of line level analysis, Calls is the number of times the line has been executed. Distribution Cover can be used in a distributed Erlang system. One of the nodes in the system must then be selected as the main node , and all Cover commands must be executed from this node. The error reason not_main_node is returned if an interface function is called on one of the remote nodes. Use cover:start/1 and cover:stop/1 to add or remove nodes. The same Cover compiled code will be loaded on each node, and analysis will collect and sum up coverage data results from all nodes. To only collect data from remote nodes without stopping cover on those nodes, use cover:flush/1 If the connection to a remote node goes down, the main node will mark it as lost. If the node comes back it will be added again. If the remote node was alive during the disconnected periode, cover data from before and during this periode will be included in the analysis. SEE ALSO code(3), compile(3)","ref":"cover.html","title":"cover","type":"module"},{"doc":"Performs analysis of one or more Cover compiled modules, as specified by Analysis and Level (see above), by examining the contents of the internal database. Analysis defaults to coverage and Level defaults to function . If Modules is an atom (one module), the return will be OneResult , else the return will be {result, Ok, Fail} . If Modules is not given, all modules that have data in the cover data table, are analysed. Note that this includes both cover compiled modules and imported modules. If a given module is not Cover compiled, this is indicated by the error reason {not_cover_compiled, Module} .","ref":"cover.html#analyse/0","title":"cover.analyse/0","type":"function"},{"doc":"","ref":"cover.html#analyse/1","title":"cover.analyse/1","type":"function"},{"doc":"","ref":"cover.html#analyse/2","title":"cover.analyse/2","type":"function"},{"doc":"","ref":"cover.html#analyse/3","title":"cover.analyse/3","type":"function"},{"doc":"Makes copies of the source file for the given modules, where it for each executable line is specified how many times it has been executed. The output file OutFile defaults to Module.COVER.out , or Module.COVER.html if the option html was used. If Modules is an atom (one module), the return will be Answer , else the return will be a list, {result, Ok, Fail} . If Modules is not given, all modules that have da ta in the cover data table, are analysed. Note that this includes both cover compiled modules and imported modules. If a module is not Cover compiled, this is indicated by the error reason {not_cover_compiled, Module} . If the source file and/or the output file cannot be opened using file:open/2 , the function returns {error, {file, File, Reason}} where File is the file name and Reason is the error reason. If a module was cover compiled from the .beam file, that is, using compile_beam/1 or compile_beam_directory/0,1 ,it is assumed that the source code can be found in the same directory as the .beam file, in ../src relative to that directory, or using the source path in Module:module_info(compile) . When using the latter, two paths are examined: first the one constructed by joining ../src and the tail of the compiled path below a trailing src component, then the compiled path itself. If no source code is found, this is indicated by the error reason {no_source_code_found, Module} .","ref":"cover.html#analyse_to_file/0","title":"cover.analyse_to_file/0","type":"function"},{"doc":"","ref":"cover.html#analyse_to_file/1","title":"cover.analyse_to_file/1","type":"function"},{"doc":"","ref":"cover.html#analyse_to_file/2","title":"cover.analyse_to_file/2","type":"function"},{"doc":"This function works exactly the same way as analyse_to_file except that it is asynchronous instead of synchronous. The spawned process will link with the caller when created. If an error of type analyse_rsn() occurs while doing the cover analysis the process will crash with the same error reason as analyse_to_file would return.","ref":"cover.html#async_analyse_to_file/1","title":"cover.async_analyse_to_file/1","type":"function"},{"doc":"","ref":"cover.html#async_analyse_to_file/2","title":"cover.async_analyse_to_file/2","type":"function"},{"doc":"","ref":"cover.html#async_analyse_to_file/3","title":"cover.async_analyse_to_file/3","type":"function"},{"doc":"See compile:file/2 . Compiles a module for Cover analysis. The module is given by its module name Module or by its file name File . The .erl extension may be omitted. If the module is located in another directory, the path has to be specified. Options is a list of compiler options which defaults to [] . Only options defining include file directories and macros are passed to compile:file/2 , everything else is ignored. If the module is successfully Cover compiled, the function returns {ok, Module} . Otherwise the function returns {error, File} . Errors and warnings are printed as they occur. If a list of ModFiles is given as input, a list of Result will be returned. The order of the returned list is undefined. Note that the internal database is (re-)initiated during the compilation, meaning any previously collected coverage data for the module will be lost.","ref":"cover.html#compile/1","title":"cover.compile/1","type":"function"},{"doc":"","ref":"cover.html#compile/2","title":"cover.compile/2","type":"function"},{"doc":"Does the same as compile/1,2 , but uses an existing .beam file as base, that is, the module is not compiled from source. Thus compile_beam/1 is faster than compile/1,2 . Note that the existing .beam file must contain abstract code , that is, it must have been compiled with the debug_info option. If not, the error reason {no_abstract_code, BeamFile} is returned. If the abstract code is encrypted, and no key is available for decrypting it, the error reason {encrypted_abstract_code, BeamFile} is returned. If only the module name (that is, not the full name of the .beam file) is given to this function, the .beam file is found by calling code:which(Module) . If no .beam file is found, the error reason non_existing is returned. If the module is already cover compiled with compile_beam/1 , the .beam file will be picked from the same location as the first time it was compiled. If the module is already cover compiled with compile/1,2 , there is no way to find the correct .beam file, so the error reason {already_cover_compiled, no_beam_found, Module} is returned. {error, BeamFile} is returned if the compiled code cannot be loaded on the node. If a list of ModFiles is given as input, a list of Result will be returned. The order of the returned list is undefined.","ref":"cover.html#compile_beam/1","title":"cover.compile_beam/1","type":"function"},{"doc":"Compiles all modules ( .beam files) in a directory Dir for Cover analysis the same way as compile_beam/1 and returns a list with the return values. Dir defaults to the current working directory. The function returns {error, eacces} if the directory is not readable or {error, enoent} if the directory does not exist.","ref":"cover.html#compile_beam_directory/0","title":"cover.compile_beam_directory/0","type":"function"},{"doc":"","ref":"cover.html#compile_beam_directory/1","title":"cover.compile_beam_directory/1","type":"function"},{"doc":"See compile:file/2 . Compiles all modules ( .erl files) in a directory Dir for Cover analysis the same way as compile_module/1,2 and returns a list with the return values. Dir defaults to the current working directory. The function returns {error, eacces} if the directory is not readable or {error, enoent} if the directory does not exist.","ref":"cover.html#compile_directory/0","title":"cover.compile_directory/0","type":"function"},{"doc":"","ref":"cover.html#compile_directory/1","title":"cover.compile_directory/1","type":"function"},{"doc":"","ref":"cover.html#compile_directory/2","title":"cover.compile_directory/2","type":"function"},{"doc":"","ref":"cover.html#compile_module/1","title":"cover.compile_module/1","type":"function"},{"doc":"","ref":"cover.html#compile_module/2","title":"cover.compile_module/2","type":"function"},{"doc":"Exports the current coverage data for Module to the file ExportFile . It is recommended to name the ExportFile with the extension .coverdata , since other filenames cannot be read by the web based interface to cover. If Module is not given, data for all Cover compiled or earlier imported modules is exported. This function is useful if coverage data from different systems is to be merged. See also import/1 .","ref":"cover.html#export/1","title":"cover.export/1","type":"function"},{"doc":"","ref":"cover.html#export/2","title":"cover.export/2","type":"function"},{"doc":"Fetch data from the Cover database on the remote nodes and stored on the main node.","ref":"cover.html#flush/1","title":"cover.flush/1","type":"function"},{"doc":"Imports coverage data from the file ExportFile created with export/1,2 . Any analysis performed after this will include the imported data. Note that when compiling a module all existing coverage data is removed , including imported data. If a module is already compiled when data is imported, the imported data is added to the existing coverage data. Coverage data from several export files can be imported into one system. The coverage data is then added up when analysing. Coverage data for a module cannot be imported from the same file twice unless the module is first reset or compiled. The check is based on the filename, so you can easily fool the system by renaming your export file. See also export/1,2 .","ref":"cover.html#import/1","title":"cover.import/1","type":"function"},{"doc":"Returns a list with all imported files.","ref":"cover.html#imported/0","title":"cover.imported/0","type":"function"},{"doc":"Returns a list with all modules for which there are imported data.","ref":"cover.html#imported_modules/0","title":"cover.imported_modules/0","type":"function"},{"doc":"Returns {file, File} if the module Module is Cover compiled, or false otherwise. File is the .erl file used by compile_module/1,2 or the .beam file used by compile_beam/1 .","ref":"cover.html#is_compiled/1","title":"cover.is_compiled/1","type":"function"},{"doc":"Only support running Cover on the local node. This function must be called before any modules have been compiled or any nodes added. When running in this mode, modules will be Cover compiled in a more efficient way, but the resulting code will only work on the same node they were compiled on.","ref":"cover.html#local_only/0","title":"cover.local_only/0","type":"function"},{"doc":"Returns a list with all modules that are currently Cover compiled.","ref":"cover.html#modules/0","title":"cover.modules/0","type":"function"},{"doc":"Resets all coverage data for a Cover compiled module Module in the Cover database on all nodes. If the argument is omitted, the coverage data will be reset for all modules known by Cover. If Module is not Cover compiled, the function returns {error, {not_cover_compiled, Module}} .","ref":"cover.html#reset/0","title":"cover.reset/0","type":"function"},{"doc":"","ref":"cover.html#reset/1","title":"cover.reset/1","type":"function"},{"doc":"Starts the Cover server which owns the Cover internal database. This function is called automatically by the other functions in the module.","ref":"cover.html#start/0","title":"cover.start/0","type":"function"},{"doc":"Starts a Cover server on the each of given nodes, and loads all cover compiled modules. This call will fail if cover:local_only/0 has been called.","ref":"cover.html#start/1","title":"cover.start/1","type":"function"},{"doc":"Stops the Cover server and unloads all Cover compiled code.","ref":"cover.html#stop/0","title":"cover.stop/0","type":"function"},{"doc":"Stops the Cover server and unloads all Cover compiled code on the given nodes. Data stored in the Cover database on the remote nodes is fetched and stored on the main node.","ref":"cover.html#stop/1","title":"cover.stop/1","type":"function"},{"doc":"Returns a list with all nodes that are part of the coverage analysis. Note that the current node is not returned. This node is always part of the analysis.","ref":"cover.html#which_nodes/0","title":"cover.which_nodes/0","type":"function"},{"doc":"The cprof module is used to profile a program to find out how many times different functions are called. Breakpoints similar to local call trace, but containing a counter, are used to minimise runtime performance impact. Since breakpoints are used there is no need for special compilation of any module to be profiled. For now these breakpoints can only be set on BEAM code so BIFs cannot be call count traced. The size of the call counters is the host machine word size. One bit is used when pausing the counter, so the maximum counter value for a 32-bit host is 2147483647. The profiling result is delivered as a term containing a sorted list of entries, one per module. Each module entry contains a sorted list of functions. The sorting order in both cases is of decreasing call count. Call count tracing is very lightweight compared to other forms of tracing since no trace message has to be generated. Some measurements indicates performance degradation in the vicinity of 10 percent. See Also eprof (3), fprof (3), erlang(3), User's Guide","ref":"cprof.html","title":"cprof","type":"module"},{"doc":"Collects and analyses the call counters presently in the node for either module Mod , or for all modules (except cprof itself), and returns: FuncAnalysisList A list of tuples, one for each function in a module, in decreasing FuncCallCount order. ModCallCount The sum of FuncCallCount values for all functions in module Mod . AllCallCount The sum of ModCallCount values for all modules concerned in ModAnalysisList . ModAnalysisList A list of tuples, one for each module except cprof , in decreasing ModCallCount order. If call counters are still running while analyse/0..2 is executing, you might get an inconsistent result. This happens if the process executing analyse/0..2 gets scheduled out so some other process can increment the counters that are being analysed, Calling pause() before analysing takes care of the problem. If the Mod argument is given, the result contains a ModAnalysis tuple for module Mod only, otherwise the result contains one ModAnalysis tuple for all modules returned from code:all_loaded() except cprof itself. All functions with a FuncCallCount lower than Limit are excluded from FuncAnalysisList . They are still included in ModCallCount , though. The default value for Limit is 1 .","ref":"cprof.html#analyse/0","title":"cprof.analyse/0","type":"function"},{"doc":"","ref":"cprof.html#analyse/1","title":"cprof.analyse/1","type":"function"},{"doc":"","ref":"cprof.html#analyse/2","title":"cprof.analyse/2","type":"function"},{"doc":"Pause call count tracing for all functions in all modules and stop it for all functions in modules to be loaded. This is the same as (pause({'_','_','_'})+stop({on_load})) . See also pause/1..3 below.","ref":"cprof.html#pause/0","title":"cprof.pause/0","type":"function"},{"doc":"Pause call counters for matching functions in matching modules. The FS argument can be used to specify the first argument to erlang:trace_pattern/3 . The call counters for all matching functions that has got call count breakpoints are paused at their current count. Return the number of matching functions that can have call count breakpoints, the same as start/0..3 with the same arguments would have returned.","ref":"cprof.html#pause/1","title":"cprof.pause/1","type":"function"},{"doc":"","ref":"cprof.html#pause/2","title":"cprof.pause/2","type":"function"},{"doc":"","ref":"cprof.html#pause/3","title":"cprof.pause/3","type":"function"},{"doc":"Restart call counters for the matching functions in matching modules that are call count traced. The FS argument can be used to specify the first argument to erlang:trace_pattern/3 . The call counters for all matching functions that has got call count breakpoints are set to zero and running. Return the number of matching functions that can have call count breakpoints, the same as start/0..3 with the same arguments would have returned.","ref":"cprof.html#restart/0","title":"cprof.restart/0","type":"function"},{"doc":"","ref":"cprof.html#restart/1","title":"cprof.restart/1","type":"function"},{"doc":"","ref":"cprof.html#restart/2","title":"cprof.restart/2","type":"function"},{"doc":"","ref":"cprof.html#restart/3","title":"cprof.restart/3","type":"function"},{"doc":"Start call count tracing for all functions in all modules, and also for all functions in modules to be loaded. This is the same as (start({'_','_','_'})+start({on_load})) . See also start/1..3 below.","ref":"cprof.html#start/0","title":"cprof.start/0","type":"function"},{"doc":"Start call count tracing for matching functions in matching modules. The FS argument can be used to specify the first argument to erlang:trace_pattern/3 , for example on_load . Set call count breakpoints on the matching functions that has no call count breakpoints. Call counters are set to zero and running for all matching functions. Return the number of matching functions that has got call count breakpoints.","ref":"cprof.html#start/1","title":"cprof.start/1","type":"function"},{"doc":"","ref":"cprof.html#start/2","title":"cprof.start/2","type":"function"},{"doc":"","ref":"cprof.html#start/3","title":"cprof.start/3","type":"function"},{"doc":"Stop call count tracing for all functions in all modules, and also for all functions in modules to be loaded. This is the same as (stop({'_','_','_'})+stop({on_load})) . See also stop/1..3 below.","ref":"cprof.html#stop/0","title":"cprof.stop/0","type":"function"},{"doc":"Stop call count tracing for matching functions in matching modules. The FS argument can be used to specify the first argument to erlang:trace_pattern/3 , for example on_load . Remove call count breakpoints from the matching functions that has call count breakpoints. Return the number of matching functions that can have call count breakpoints, the same as start/0..3 with the same arguments would have returned.","ref":"cprof.html#stop/1","title":"cprof.stop/1","type":"function"},{"doc":"","ref":"cprof.html#stop/2","title":"cprof.stop/2","type":"function"},{"doc":"","ref":"cprof.html#stop/3","title":"cprof.stop/3","type":"function"},{"doc":"The module eprof provides a set of functions for time profiling of Erlang programs to find out how the execution time is used. The profiling is done using the Erlang trace BIFs. Tracing of local function calls for a specified set of processes is enabled when profiling is begun, and disabled when profiling is stopped. When using Eprof, expect a slowdown in program execution.","ref":"eprof.html","title":"eprof","type":"module"},{"doc":"Call this function when profiling has been stopped to display the results per process, that is: how much time has been used by each process, and in which function calls this time has been spent. Call analyze with total option when profiling has been stopped to display the results per function call, that is in which function calls the time has been spent. Time is shown as percentage of total time and as absolute time.","ref":"eprof.html#analyze/0","title":"eprof.analyze/0","type":"function"},{"doc":"","ref":"eprof.html#analyze/1","title":"eprof.analyze/1","type":"function"},{"doc":"","ref":"eprof.html#analyze/2","title":"eprof.analyze/2","type":"function"},{"doc":"This function ensures that the results displayed by analyze/0,1,2 are printed both to the file File and the screen.","ref":"eprof.html#log/1","title":"eprof.log/1","type":"function"},{"doc":"This function first spawns a process P which evaluates Fun() or apply(Module,Function,Args) . Then, it starts profiling for P and the processes in Rootset (and any new processes spawned from them). Information about activity in any profiled process is stored in the Eprof database. Rootset is a list of pids and registered names. If tracing could be enabled for P and all processes in Rootset , the function returns {ok,Value} when Fun() / apply returns with the value Value , or {error,Reason} if Fun() / apply fails with exit reason Reason . Otherwise it returns {error, Reason} immediately. The set_on_spawn option will active call time tracing for all processes spawned by processes in the rootset. This is the default behaviour. The programmer must ensure that the function given as argument is truly synchronous and that no work continues after the function has returned a value.","ref":"eprof.html#profile/1","title":"eprof.profile/1","type":"function"},{"doc":"","ref":"eprof.html#profile/2","title":"eprof.profile/2","type":"function"},{"doc":"","ref":"eprof.html#profile/3","title":"eprof.profile/3","type":"function"},{"doc":"","ref":"eprof.html#profile/4","title":"eprof.profile/4","type":"function"},{"doc":"","ref":"eprof.html#profile/5","title":"eprof.profile/5","type":"function"},{"doc":"","ref":"eprof.html#profile/6","title":"eprof.profile/6","type":"function"},{"doc":"Starts the Eprof server which holds the internal state of the collected data.","ref":"eprof.html#start/0","title":"eprof.start/0","type":"function"},{"doc":"Starts profiling for the processes in Rootset (and any new processes spawned from them). Information about activity in any profiled process is stored in the Eprof database. Rootset is a list of pids and registered names. The function returns profiling if tracing could be enabled for all processes in Rootset , or error otherwise. A pattern can be selected to narrow the profiling. For instance a specific module can be selected, and only the code executed in that module will be profiled. The set_on_spawn option will active call time tracing for all processes spawned by processes in the rootset. This is the default behaviour.","ref":"eprof.html#start_profiling/1","title":"eprof.start_profiling/1","type":"function"},{"doc":"","ref":"eprof.html#start_profiling/2","title":"eprof.start_profiling/2","type":"function"},{"doc":"","ref":"eprof.html#start_profiling/3","title":"eprof.start_profiling/3","type":"function"},{"doc":"Stops the Eprof server.","ref":"eprof.html#stop/0","title":"eprof.stop/0","type":"function"},{"doc":"Stops profiling started with start_profiling/1 or prifile/1 .","ref":"eprof.html#stop_profiling/0","title":"eprof.stop_profiling/0","type":"function"},{"doc":"This module is used to profile a program to find out how the execution time is used. Trace to file is used to minimize runtime performance impact. The fprof module uses tracing to collect profiling data, hence there is no need for special compilation of any module to be profiled. When it starts tracing, fprof will erase all previous tracing in the node and set the necessary trace flags on the profiling target processes as well as local call trace on all functions in all loaded modules and all modules to be loaded. fprof erases all tracing in the node when it stops tracing. fprof presents both own time i.e how much time a function has used for its own execution, and accumulated time i.e including called functions. All presented times are collected using trace timestamps. fprof tries to collect cpu time timestamps, if the host machine OS supports it. Therefore the times may be wallclock times and OS scheduling will randomly strike all called functions in a presumably fair way. If, however, the profiling time is short, and the host machine OS does not support high resolution cpu time measurements, some few OS schedulings may show up as ridiculously long execution times for functions doing practically nothing. An example of a function more or less just composing a tuple in about 100 times the normal execution time has been seen, and when the tracing was repeated, the execution time became normal. Profiling is essentially done in 3 steps: 1 Tracing; to file, as mentioned in the previous paragraph. The trace contains entries for function calls, returns to function, process scheduling, other process related (spawn, etc) events, and garbage collection. All trace entries are timestamped. 2 Profiling; the trace file is read, the execution call stack is simulated, and raw profile data is calculated from the simulated call stack and the trace timestamps. The profile data is stored in the fprof server state. During this step the trace data may be dumped in text format to file or console. 3 Analysing; the raw profile data is sorted, filtered and dumped in text format either to file or console. The text format intended to be both readable for a human reader, as well as parsable with the standard erlang parsing tools. Since fprof uses trace to file, the runtime performance degradation is minimized, but still far from negligible, especially for programs that use the filesystem heavily by themselves. Where you place the trace file is also important, e.g on Solaris /tmp is usually a good choice since it is essentially a RAM disk, while any NFS (network) mounted disk is a bad idea. fprof can also skip the file step and trace to a tracer process that does the profiling in runtime. Analysis format This section describes the output format of the analyse command. See analyse/0 . The format is parsable with the standard Erlang parsing tools erl_scan and erl_parse , file:consult/1 or io:read/2 . The parse format is not explained here - it should be easy for the interested to try it out. Note that some flags to analyse/1 will affect the format. The following example was run on OTP/R8 on Solaris 8, all OTP internals in this example are very version dependent. As an example, we will use the following function, that you may recognise as a slightly modified benchmark function from the manpage file(3): -module(foo). -export([create_file_slow/2]). create_file_slow(Name, N) when is_integer(N), N &gt;= 0 -&gt; {ok, FD} = file:open(Name, [raw, write, delayed_write, binary]), if N &gt; 256 -&gt; ok = file:write(FD, lists:map(fun (X) -&gt; &lt;&lt;X:32/unsigned&gt;&gt; end, lists:seq(0, 255))), ok = create_file_slow(FD, 256, N); true -&gt; ok = create_file_slow(FD, 0, N) end, ok = file:close(FD). create_file_slow(FD, M, M) -&gt; ok; create_file_slow(FD, M, N) -&gt; ok = file:write(FD, &lt;&lt;M:32/unsigned&gt;&gt;), create_file_slow(FD, M+1, N). Let us have a look at the printout after running: 1 &gt; fprof : apply ( foo , create_file_slow , [ junk , 1024 ] ) . 2 &gt; fprof : profile ( ) . 3 &gt; fprof : analyse ( ) . The printout starts with: %% Analysis results: { analysis_options , [ { callers , true } , { sort , acc } , { totals , false } , { details , true } ] } . % CNT ACC OWN [ { totals , 9627 , 1691.119 , 1659.074 } ] . %%% The CNT column shows the total number of function calls that was found in the trace. In the ACC column is the total time of the trace from first timestamp to last. And in the OWN column is the sum of the execution time in functions found in the trace, not including called functions. In this case it is very close to the ACC time since the emulator had practically nothing else to do than to execute our test program. All time values in the printout are in milliseconds. The printout continues: % CNT ACC OWN [ { &quot;&lt;0.28.0&gt;&quot; , 9627 , undefined , 1659.074 } ] . %% This is the printout header of one process. The printout contains only this one process since we did fprof:apply/3 which traces only the current process. Therefore the CNT and OWN columns perfectly matches the totals above. The ACC column is undefined since summing the ACC times of all calls in the process makes no sense - you would get something like the ACC value from totals above multiplied by the average depth of the call stack, or something. All paragraphs up to the next process header only concerns function calls within this process. Now we come to something more interesting: { [ { undefined , 0 , 1691.076 , 0.030 } ] , { { fprof , apply_start_stop , 4 } , 0 , 1691.076 , 0.030 } , % [ { { foo , create_file_slow , 2 } , 1 , 1691.046 , 0.103 } , { suspend , 1 , 0.000 , 0.000 } ] } . { [ { { fprof , apply_start_stop , 4 } , 1 , 1691.046 , 0.103 } ] , { { foo , create_file_slow , 2 } , 1 , 1691.046 , 0.103 } , % [ { { file , close , 1 } , 1 , 1398.873 , 0.019 } , { { foo , create_file_slow , 3 } , 1 , 249.678 , 0.029 } , { { file , open , 2 } , 1 , 20.778 , 0.055 } , { { lists , map , 2 } , 1 , 16.590 , 0.043 } , { { lists , seq , 2 } , 1 , 4.708 , 0.017 } , { { file , write , 2 } , 1 , 0.316 , 0.021 } ] } . The printout consists of one paragraph per called function. The function marked with '%' is the one the paragraph concerns - foo:create_file_slow/2 . Above the marked function are the calling functions - those that has called the marked, and below are those called by the marked function. The paragraphs are per default sorted in decreasing order of the ACC column for the marked function. The calling list and called list within one paragraph are also per default sorted in decreasing order of their ACC column. The columns are: CNT - the number of times the function has been called, ACC - the time spent in the function including called functions, and OWN - the time spent in the function not including called functions. The rows for the calling functions contain statistics for the marked function with the constraint that only the occasions when a call was made from the row's function to the marked function are accounted for. The row for the marked function simply contains the sum of all calling rows. The rows for the called functions contains statistics for the row's function with the constraint that only the occasions when a call was made from the marked to the row's function are accounted for. So, we see that foo:create_file_slow/2 used very little time for its own execution. It spent most of its time in file:close/1 . The function foo:create_file_slow/3 that writes 3/4 of the file contents is the second biggest time thief. We also see that the call to file:write/2 that writes 1/4 of the file contents takes very little time in itself. What takes time is to build the data ( lists:seq/2 and lists:map/2 ). The function 'undefined' that has called fprof:apply_start_stop/4 is an unknown function because that call was not recorded in the trace. It was only recorded that the execution returned from fprof:apply_start_stop/4 to some other function above in the call stack, or that the process exited from there. Let us continue down the printout to find: { [ { { foo , create_file_slow , 2 } , 1 , 249.678 , 0.029 } , { { foo , create_file_slow , 3 } , 768 , 0.000 , 23.294 } ] , { { foo , create_file_slow , 3 } , 769 , 249.678 , 23.323 } , % [ { { file , write , 2 } , 768 , 220.314 , 14.539 } , { suspend , 57 , 6.041 , 0.000 } , { { foo , create_file_slow , 3 } , 768 , 0.000 , 23.294 } ] } . If you compare with the code you will see there also that foo:create_file_slow/3 was called only from foo:create_file_slow/2 and itself, and called only file:write/2 , note the number of calls to file:write/2 . But here we see that suspend was called a few times. This is a pseudo function that indicates that the process was suspended while executing in foo:create_file_slow/3 , and since there is no receive or erlang:yield/0 in the code, it must be Erlang scheduling suspensions, or the trace file driver compensating for large file write operations (these are regarded as a schedule out followed by a schedule in to the same process). Let us find the suspend entry: { [ { { file , write , 2 } , 53 , 6.281 , 0.000 } , { { foo , create_file_slow , 3 } , 57 , 6.041 , 0.000 } , { { prim_file , drv_command , 4 } , 50 , 4.582 , 0.000 } , { { prim_file , drv_get_response , 1 } , 34 , 2.986 , 0.000 } , { { lists , map , 2 } , 10 , 2.104 , 0.000 } , { { prim_file , write , 2 } , 17 , 1.852 , 0.000 } , { { erlang , port_command , 2 } , 15 , 1.713 , 0.000 } , { { prim_file , drv_command , 2 } , 22 , 1.482 , 0.000 } , { { prim_file , translate_response , 2 } , 11 , 1.441 , 0.000 } , { { prim_file , &#39;-drv_command/2-fun-0-&#39; , 1 } , 15 , 1.340 , 0.000 } , { { lists , seq , 4 } , 3 , 0.880 , 0.000 } , { { foo , &#39;-create_file_slow/2-fun-0-&#39; , 1 } , 5 , 0.523 , 0.000 } , { { erlang , bump_reductions , 1 } , 4 , 0.503 , 0.000 } , { { prim_file , open_int_setopts , 3 } , 1 , 0.165 , 0.000 } , { { prim_file , i32 , 4 } , 1 , 0.109 , 0.000 } , { { fprof , apply_start_stop , 4 } , 1 , 0.000 , 0.000 } ] , { suspend , 299 , 32.002 , 0.000 } , % [ ] } . We find no particulary long suspend times, so no function seems to have waited in a receive statement. Actually, prim_file:drv_command/4 contains a receive statement, but in this test program, the message lies in the process receive buffer when the receive statement is entered. We also see that the total suspend time for the test run is small. The suspend pseudo function has got an OWN time of zero. This is to prevent the process total OWN time from including time in suspension. Whether suspend time is really ACC or OWN time is more of a philosophical question. Now we look at another interesting pseudo function, garbage_collect : { [ { { prim_file , drv_command , 4 } , 25 , 0.873 , 0.873 } , { { prim_file , write , 2 } , 16 , 0.692 , 0.692 } , { { lists , map , 2 } , 2 , 0.195 , 0.195 } ] , { garbage_collect , 43 , 1.760 , 1.760 } , % [ ] } . Here we see that no function distinguishes itself considerably, which is very normal. The garbage_collect pseudo function has not got an OWN time of zero like suspend , instead it is equal to the ACC time. Garbage collect often occurs while a process is suspended, but fprof hides this fact by pretending that the suspended function was first unsuspended and then garbage collected. Otherwise the printout would show garbage_collect being called from suspend but not which function that might have caused the garbage collection. Let us now get back to the test code: { [ { { foo , create_file_slow , 3 } , 768 , 220.314 , 14.539 } , { { foo , create_file_slow , 2 } , 1 , 0.316 , 0.021 } ] , { { file , write , 2 } , 769 , 220.630 , 14.560 } , % [ { { prim_file , write , 2 } , 769 , 199.789 , 22.573 } , { suspend , 53 , 6.281 , 0.000 } ] } . Not unexpectedly, we see that file:write/2 was called from foo:create_file_slow/3 and foo:create_file_slow/2 . The number of calls in each case as well as the used time are also just confirms the previous results. We see that file:write/2 only calls prim_file:write/2 , but let us refrain from digging into the internals of the kernel application. But, if we nevertheless do dig down we find the call to the linked in driver that does the file operations towards the host operating system: { [ { { prim_file , drv_command , 4 } , 772 , 1458.356 , 1456.643 } ] , { { erlang , port_command , 2 } , 772 , 1458.356 , 1456.643 } , % [ { suspend , 15 , 1.713 , 0.000 } ] } . This is 86 % of the total run time, and as we saw before it is the close operation the absolutely biggest contributor. We find a comparison ratio a little bit up in the call stack: { [ { { prim_file , close , 1 } , 1 , 1398.748 , 0.024 } , { { prim_file , write , 2 } , 769 , 174.672 , 12.810 } , { { prim_file , open_int , 4 } , 1 , 19.755 , 0.017 } , { { prim_file , open_int_setopts , 3 } , 1 , 0.147 , 0.016 } ] , { { prim_file , drv_command , 2 } , 772 , 1593.322 , 12.867 } , % [ { { prim_file , drv_command , 4 } , 772 , 1578.973 , 27.265 } , { suspend , 22 , 1.482 , 0.000 } ] } . The time for file operations in the linked in driver distributes itself as 1 % for open, 11 % for write and 87 % for close. All data is probably buffered in the operating system until the close. The unsleeping reader may notice that the ACC times for prim_file:drv_command/2 and prim_file:drv_command/4 is not equal between the paragraphs above, even though it is easy to believe that prim_file:drv_command/2 is just a passthrough function. The missing time can be found in the paragraph for prim_file:drv_command/4 where it is evident that not only prim_file:drv_command/2 is called but also a fun: { [ { { prim_file , drv_command , 2 } , 772 , 1578.973 , 27.265 } ] , { { prim_file , drv_command , 4 } , 772 , 1578.973 , 27.265 } , % [ { { erlang , port_command , 2 } , 772 , 1458.356 , 1456.643 } , { { prim_file , &#39;-drv_command/2-fun-0-&#39; , 1 } , 772 , 87.897 , 12.736 } , { suspend , 50 , 4.582 , 0.000 } , { garbage_collect , 25 , 0.873 , 0.873 } ] } . And some more missing time can be explained by the fact that prim_file:open_int/4 both calls prim_file:drv_command/2 directly as well as through prim_file:open_int_setopts/3 , which complicates the picture. { [ { { prim_file , open , 2 } , 1 , 20.309 , 0.029 } , { { prim_file , open_int , 4 } , 1 , 0.000 , 0.057 } ] , { { prim_file , open_int , 4 } , 2 , 20.309 , 0.086 } , % [ { { prim_file , drv_command , 2 } , 1 , 19.755 , 0.017 } , { { prim_file , open_int_setopts , 3 } , 1 , 0.360 , 0.032 } , { { prim_file , drv_open , 2 } , 1 , 0.071 , 0.030 } , { { erlang , list_to_binary , 1 } , 1 , 0.020 , 0.020 } , { { prim_file , i32 , 1 } , 1 , 0.017 , 0.017 } , { { prim_file , open_int , 4 } , 1 , 0.000 , 0.057 } ] } . . . . { [ { { prim_file , open_int , 4 } , 1 , 0.360 , 0.032 } , { { prim_file , open_int_setopts , 3 } , 1 , 0.000 , 0.016 } ] , { { prim_file , open_int_setopts , 3 } , 2 , 0.360 , 0.048 } , % [ { suspend , 1 , 0.165 , 0.000 } , { { prim_file , drv_command , 2 } , 1 , 0.147 , 0.016 } , { { prim_file , open_int_setopts , 3 } , 1 , 0.000 , 0.016 } ] } . Notes The actual supervision of execution times is in itself a CPU intensive activity. A message is written on the trace file for every function call that is made by the profiled code. The ACC time calculation is sometimes difficult to make correct, since it is difficult to define. This happens especially when a function occurs in several instances in the call stack, for example by calling itself perhaps through other functions and perhaps even non-tail recursively. To produce sensible results, fprof tries not to charge any function more than once for ACC time. The instance highest up (with longest duration) in the call stack is chosen. Sometimes a function may unexpectedly waste a lot (some 10 ms or more depending on host machine OS) of OWN (and ACC) time, even functions that do practically nothing at all. The problem may be that the OS has chosen to schedule out the Erlang runtime system process for a while, and if the OS does not support high resolution cpu time measurements fprof will use wallclock time for its calculations, and it will appear as functions randomly burn virtual machine time. See Also dbg(3), eprof (3), erlang(3), io(3), Tools User's Guide","ref":"fprof.html","title":"fprof","type":"module"},{"doc":"Same as analyse([]) .","ref":"fprof.html#analyse/0","title":"fprof.analyse/0","type":"function"},{"doc":"Same as analyse([OptionName]) .","ref":"fprof.html#analyse/1","title":"fprof.analyse/1","type":"function"},{"doc":"Same as analyse([{OptionName, OptionValue}]) .","ref":"fprof.html#analyse/1","title":"fprof.analyse/1","type":"function"},{"doc":"Analyses raw profile data in the fprof  server. If called while there is no raw profile data available, {error, no_profile} is returned. Destfile is used to call file:open/2 . Option description: dest | {dest, Dest} Specifies the destination for the analysis. If this option is not given or it is dest , the destination will be the caller's group leader, otherwise the destination Dest is either the pid() of an I/O device or a filename. And, finally, if the filename is [] - &quot;fprof.analysis&quot; is used instead. append Causes the analysis to be appended to the destination file. This option is only allowed with the {dest, Destfile} option. {cols, Cols} Specifies the number of columns in the analysis text. If this option is not given the number of columns is set to 80. callers | {callers, true} Prints callers and called information in the analysis. This is the default. {callers, false} | no_callers Suppresses the printing of callers and called information in the analysis. {sort, SortSpec} Specifies if the analysis should be sorted according to the ACC column, which is the default, or the OWN column. See Analysis Format below. totals | {totals, true} Includes a section containing call statistics for all calls regardless of process, in the analysis. {totals, false} Supresses the totals section in the analysis, which is the default. details | {details, true} Prints call statistics for each process in the analysis. This is the default. {details, false} | no_details Suppresses the call statistics for each process from the analysis.","ref":"fprof.html#analyse/1","title":"fprof.analyse/1","type":"function"},{"doc":"Same as analyse([{OptionName, OptionValue}]) .","ref":"fprof.html#analyse/2","title":"fprof.analyse/2","type":"function"},{"doc":"Same as apply(Func, Args, []) .","ref":"fprof.html#apply/2","title":"fprof.apply/2","type":"function"},{"doc":"Same as apply({Module, Function}, Args, []) .","ref":"fprof.html#apply/3","title":"fprof.apply/3","type":"function"},{"doc":"Calls erlang:apply(Func, Args) surrounded by trace([start, ...]) and trace(stop) . Some effort is made to keep the trace clean from unnecessary trace messages; tracing is started and stopped from a spawned process while the erlang:apply/2 call is made in the current process, only surrounded by receive and send statements towards the trace starting process. The trace starting process exits when not needed any more. The TraceStartOption is any option allowed for trace/1 . The options [start, {procs, [self() | PidList]} | OptList] are given to trace/1 , where OptList is OptionList with continue , start and {procs, _} options removed. The continue option inhibits the call to trace(stop) and leaves it up to the caller to stop tracing at a suitable time.","ref":"fprof.html#apply/3","title":"fprof.apply/3","type":"function"},{"doc":"Same as apply({Module, Function}, Args, OptionList) . OptionList is an option list allowed for apply/3 .","ref":"fprof.html#apply/4","title":"fprof.apply/4","type":"function"},{"doc":"Same as profile([]) .","ref":"fprof.html#profile/0","title":"fprof.profile/0","type":"function"},{"doc":"Same as profile([OptionName]) .","ref":"fprof.html#profile/1","title":"fprof.profile/1","type":"function"},{"doc":"Same as profile([{OptionName, OptionValue}]) .","ref":"fprof.html#profile/1","title":"fprof.profile/1","type":"function"},{"doc":"Compiles a trace into raw profile data held by the fprof  server. Dumpfile is used to call file:open/2 , and Filename is used to call dbg:trace_port(file, Filename) . Please see file:open/2 and dbg:trace_port/2 . Option description: file | {file, Filename} Reads the file Filename and creates raw profile data that is stored in RAM by the fprof  server. If the option file is given, or none of these options are given, the file &quot;fprof.trace&quot; is read. The call will return when the whole trace has been read with the return value ok if successful. This option is not allowed with the start or stop options. dump | {dump, Dump} Specifies the destination for the trace text dump. If this option is not given, no dump is generated, if it is dump the destination will be the caller's group leader, otherwise the destination Dump is either the pid of an I/O device or a filename. And, finally, if the filename is [] - &quot;fprof.dump&quot; is used instead. This option is not allowed with the stop option. append Causes the trace text dump to be appended to the destination file. This option is only allowed with the {dump, Dumpfile} option. start Starts a tracer process that profiles trace data in runtime. The call will return immediately with the return value {ok, Tracer} if successful. This option is not allowed with the stop , file or {file, Filename} options. stop Stops the tracer process that profiles trace data in runtime. The return value will be value ok if successful. This option is not allowed with the start , file or {file, Filename} options.","ref":"fprof.html#profile/1","title":"fprof.profile/1","type":"function"},{"doc":"Same as profile([{OptionName, OptionValue}]) .","ref":"fprof.html#profile/2","title":"fprof.profile/2","type":"function"},{"doc":"Starts the fprof  server. Note that it seldom needs to be started explicitly since it is automatically started by the functions that need a running server.","ref":"fprof.html#start/0","title":"fprof.start/0","type":"function"},{"doc":"Same as stop(normal) .","ref":"fprof.html#stop/0","title":"fprof.stop/0","type":"function"},{"doc":"Stops the fprof  server. The supplied Reason becomes the exit reason for the server process. Default Any Reason other than kill sends a request to the server and waits for it to clean up, reply and exit. If Reason is kill , the server is bluntly killed. If the fprof  server is not running, this function returns immediately with the same return value. When the fprof  server is stopped the collected raw profile data is lost.","ref":"fprof.html#stop/1","title":"fprof.stop/1","type":"function"},{"doc":"Same as trace([start, verbose]) .","ref":"fprof.html#trace/1","title":"fprof.trace/1","type":"function"},{"doc":"Same as trace([OptionName]) .","ref":"fprof.html#trace/1","title":"fprof.trace/1","type":"function"},{"doc":"Same as trace([{OptionName, OptionValue}]) .","ref":"fprof.html#trace/1","title":"fprof.trace/1","type":"function"},{"doc":"Starts or stops tracing. PidSpec and Tracer are used in calls to erlang:trace(PidSpec, true, [{tracer, Tracer} | Flags]) , and Filename is used to call dbg:trace_port(file, Filename) . Please see erlang:trace/3 and dbg:trace_port/2 . Option description: stop Stops a running fprof trace and clears all tracing from the node. Either option stop or start must be specified, but not both. start Clears all tracing from the node and starts a new fprof trace. Either option start or stop must be specified, but not both. verbose | {verbose, boolean()} The options verbose or {verbose, true} adds some trace flags that fprof does not need, but that may be interesting for general debugging purposes. This option is only allowed with the start option. cpu_time | {cpu_time, boolean()} The options cpu_time or {cpu_time, true} makes the timestamps in the trace be in CPU time instead of wallclock time which is the default. This option is only allowed with the start option. Getting correct values out of cpu_time can be difficult. The best way to get correct values is to run using a single scheduler and bind that scheduler to a specific CPU, i.e. erl +S 1 +sbt db . {procs, PidSpec} | {procs, [PidSpec]} Specifies which processes that shall be traced. If this option is not given, the calling process is traced. All processes spawned by the traced processes are also traced. This option is only allowed with the start option. file | {file, Filename} Specifies the filename of the trace. If the option file is given, or none of these options are given, the file &quot;fprof.trace&quot; is used. This option is only allowed with the start option, but not with the {tracer, Tracer} option. {tracer, Tracer} Specifies that trace to process or port shall be done instead of trace to file. This option is only allowed with the start option, but not with the {file, Filename} option.","ref":"fprof.html#trace/1","title":"fprof.trace/1","type":"function"},{"doc":"Same as trace([start, {file, Filename}]) .","ref":"fprof.html#trace/2","title":"fprof.trace/2","type":"function"},{"doc":"Same as trace([start, verbose, {file, Filename}]) .","ref":"fprof.html#trace/2","title":"fprof.trace/2","type":"function"},{"doc":"Same as trace([{OptionName, OptionValue}]) .","ref":"fprof.html#trace/2","title":"fprof.trace/2","type":"function"},{"doc":"The module instrument contains support for studying the resource usage in an Erlang runtime system. Currently, only the allocation of memory can be studied. Note that this whole module is experimental, and the representations used as well as the functionality is likely to change in the future. See Also erts_alloc(3), erl(1)","ref":"instrument.html","title":"instrument","type":"module"},{"doc":"Shorthand for allocations(\#{}) .","ref":"instrument.html#allocations/0","title":"instrument.allocations/0","type":"function"},{"doc":"Returns a summary of all tagged allocations in the system, optionally filtered by allocator type and scheduler id. Only binaries and allocations made by NIFs and drivers are tagged by default, but this can be configured an a per-allocator basis with the +M&lt;S&gt;atags emulator option. If the specified allocator types are not enabled, the call will fail with {error, not_enabled} . The following options can be used: allocator_types The allocator types that will be searched. Note that blocks can move freely between allocator types, so restricting the search to certain allocators may return unexpected types (e.g. process heaps when searching binary_alloc), or hide blocks that were migrated out. Defaults to all alloc_util allocators. scheduler_ids The scheduler ids whose allocator instances will be searched. A scheduler id of 0 will refer to the global instance that is not tied to any particular scheduler. Defaults to all schedulers and the global instance. histogram_start The upper bound of the first interval in the allocated block size histograms. Defaults to 128. histogram_width The number of intervals in the allocated block size histograms. Defaults to 18. Example: &gt; instrument:allocations(\#{ histogram_start =&gt; 128, histogram_width =&gt; 15 }). {ok,{128,0, \#{udp_inet =&gt; \#{driver_event_state =&gt; {0,0,0,0,0,0,0,0,0,1,0,0,0,0,0}}, system =&gt; \#{heap =&gt; {0,0,0,0,20,4,2,2,2,3,0,1,0,0,1}, db_term =&gt; {271,3,1,52,80,1,0,0,0,0,0,0,0,0,0}, code =&gt; {0,0,0,5,3,6,11,22,19,20,10,2,1,0,0}, binary =&gt; {18,0,0,0,7,0,0,1,0,0,0,0,0,0,0}, message =&gt; {0,40,78,2,2,0,0,0,0,0,0,0,0,0,0}, ... } spawn_forker =&gt; \#{driver_select_data_state =&gt; {1,0,0,0,0,0,0,0,0,0,0,0,0,0,0}}, ram_file_drv =&gt; \#{drv_binary =&gt; {0,0,0,0,0,0,1,0,0,0,0,0,0,0,0}}, prim_file =&gt; \#{process_specific_data =&gt; {2,0,0,0,0,0,0,0,0,0,0,0,0,0,0}, nif_trap_export_entry =&gt; {0,4,0,0,0,0,0,0,0,0,0,0,0,0,0}, monitor_extended =&gt; {0,1,0,0,0,0,0,0,0,0,0,0,0,0,0}, drv_binary =&gt; {0,0,0,0,0,0,1,0,3,5,0,0,0,1,0}, binary =&gt; {0,4,0,0,0,0,0,0,0,0,0,0,0,0,0}}, prim_buffer =&gt; \#{nif_internal =&gt; {0,4,0,0,0,0,0,0,0,0,0,0,0,0,0}, binary =&gt; {0,4,0,0,0,0,0,0,0,0,0,0,0,0,0}}}}}","ref":"instrument.html#allocations/1","title":"instrument.allocations/1","type":"function"},{"doc":"Shorthand for carriers(\#{}) .","ref":"instrument.html#carriers/0","title":"instrument.carriers/0","type":"function"},{"doc":"Returns a summary of all carriers in the system, optionally filtered by allocator type and scheduler id. If the specified allocator types are not enabled, the call will fail with {error, not_enabled} . The following options can be used: allocator_types The allocator types that will be searched. Defaults to all alloc_util allocators. scheduler_ids The scheduler ids whose allocator instances will be searched. A scheduler id of 0 will refer to the global instance that is not tied to any particular scheduler. Defaults to all schedulers and the global instance. histogram_start The upper bound of the first interval in the free block size histograms. Defaults to 512. histogram_width The number of intervals in the free block size histograms. Defaults to 14. Example: &gt; instrument:carriers(\#{ histogram_start =&gt; 512, histogram_width =&gt; 8 }). {ok,{512, [{ll_alloc,1048576,0,1048344,71,false,{0,0,0,0,0,0,0,0}}, {binary_alloc,1048576,0,324640,13,false,{3,0,0,1,0,0,0,2}}, {eheap_alloc,2097152,0,1037200,45,false,{2,1,1,3,4,3,2,2}}, {fix_alloc,32768,0,29544,82,false,{22,0,0,0,0,0,0,0}}, {...}|...]}}","ref":"instrument.html#carriers/1","title":"instrument.carriers/1","type":"function"},{"doc":"A summary of allocated block sizes (including their headers) grouped by their Origin and Type . Origin is generally which NIF or driver that allocated the blocks, or 'system' if it could not be determined. Type is the allocation category that the blocks belong to, e.g. db_term , message or binary . If one or more carriers could not be scanned in full without harming the responsiveness of the system, UnscannedSize is the number of bytes that had to be skipped.","ref":"instrument.html#t:allocation_summary/0","title":"instrument.allocation_summary/0","type":"type"},{"doc":"A histogram of block sizes where each interval's upper bound is twice as high as the one before it. The upper bound of the first interval is provided by the function that returned the histogram, and the last interval has no upper bound.","ref":"instrument.html#t:block_histogram/0","title":"instrument.block_histogram/0","type":"type"},{"doc":"AllocatorType is the type of the allocator that employs this carrier. InPool is whether the carrier is in the migration pool. TotalSize is the total size of the carrier, including its header. Allocations is a summary of the allocated blocks in the carrier. FreeBlocks is a histogram of the free block sizes in the carrier. If the carrier could not be scanned in full without harming the responsiveness of the system, UnscannedSize is the number of bytes that had to be skipped.","ref":"instrument.html#t:carrier_info_list/0","title":"instrument.carrier_info_list/0","type":"type"},{"doc":"The lcnt module is used to profile the internal ethread locks in the Erlang Runtime System. With lcnt enabled, internal counters in the runtime system are updated each time a lock is taken. The counters stores information about the number of acquisition tries and the number of collisions that has occurred during the acquisition tries. The counters also record the waiting time a lock has caused for a blocked thread when a collision has occurred. The data produced by the lock counters will give an estimate on how well the runtime system will behave from a parallelizable view point for the scenarios tested. This tool was mainly developed to help Erlang runtime developers iron out potential and generic bottlenecks. Locks in the emulator are named after what type of resource they protect and where in the emulator they are initialized, those are lock 'classes'. Most of those locks are also instantiated several times, and given unique identifiers, to increase locking granularity. Typically an instantiated lock protects a disjunct set of the resource, for example ets tables, processes or ports. In other cases it protects a specific range of a resource, for example pix_lock which protects index to process mappings, and is given a unique number within the class. A unique lock in lcnt is referenced by a name (class) and an identifier: {Name, Id} . Some locks in the system are static and protects global resources, for example bif_timers and the run_queue locks. Other locks are dynamic and not necessarily long lived, for example process locks and ets-table locks. The statistics data from short lived locks can be stored separately when the locks are deleted. This behavior is by default turned off to save memory but can be turned on via lcnt:rt_opt({copy_save, true}) . The lcnt:apply/1,2,3 functions enables this behavior during profiling. See Also LCNT User's Guide","ref":"lcnt.html","title":"lcnt","type":"module"},{"doc":"Same as apply(Fun, []) .","ref":"lcnt.html#apply/1","title":"lcnt.apply/1","type":"function"},{"doc":"Clears the lock counters and then setups the instrumentation to save all destroyed locks. After setup the function is called, passing the elements in Args as arguments. When the function returns the statistics are immediately collected to the server. After the collection the instrumentation is returned to its previous behavior. The result of the applied function is returned. This function should only be used for micro-benchmarks; it sets copy_save to true for the duration of the call, which can quickly lead to running out of memory.","ref":"lcnt.html#apply/2","title":"lcnt.apply/2","type":"function"},{"doc":"Same as apply(fun() -&gt; erlang:apply(Module, Function, Args) end) .","ref":"lcnt.html#apply/3","title":"lcnt.apply/3","type":"function"},{"doc":"Same as clear(node()) .","ref":"lcnt.html#clear/0","title":"lcnt.clear/0","type":"function"},{"doc":"Clears the internal lock statistics from the runtime system. This does not clear the data on the server only on runtime system. All counters for static locks are zeroed, all dynamic locks currently alive are zeroed and all saved locks now destroyed are removed. It also resets the duration timer.","ref":"lcnt.html#clear/1","title":"lcnt.clear/1","type":"function"},{"doc":"Same as collect(node()) .","ref":"lcnt.html#collect/0","title":"lcnt.collect/0","type":"function"},{"doc":"Collects lock statistics from the runtime system. The function starts a server if it is not already started. It then populates the server with lock statistics. If the server held any lock statistics data before the collect then that data is lost.","ref":"lcnt.html#collect/1","title":"lcnt.collect/1","type":"function"},{"doc":"Same as conflicts([]) .","ref":"lcnt.html#conflicts/0","title":"lcnt.conflicts/0","type":"function"},{"doc":"Prints a list of internal locks and its statistics. For option description, see lcnt:inspect/2 .","ref":"lcnt.html#conflicts/1","title":"lcnt.conflicts/1","type":"function"},{"doc":"Prints lcnt server state and generic information about collected lock statistics.","ref":"lcnt.html#information/0","title":"lcnt.information/0","type":"function"},{"doc":"Same as inspect(Lock, []) .","ref":"lcnt.html#inspect/1","title":"lcnt.inspect/1","type":"function"},{"doc":"Prints a list of internal lock counters for a specific lock. Lock Name and Id for ports and processes are interchangeable with the use of lcnt:swap_pid_keys/0 and is the reason why pid() and port() options can be used in both Name and Id space. Both pids and ports are special identifiers with stripped creation and can be recreated with lcnt:pid/2,3 and lcnt:port/1,2 . Option description: {combine, boolean()} Combine the statistics from different instances of a lock class. Default: true {locations, boolean()} Print the statistics by source file and line numbers. Default: false {max_locks, MaxLocks} Maximum number of locks printed or no limit with none . Default: 20 {print, PrintOptions} Printing options: name Named lock or named set of locks (classes). The same name used for initializing the lock in the VM. id Internal id for set of locks, not always unique. This could be table name for ets tables (db_tab), port id for ports, integer identifiers for allocators, etc. type Type of lock: rw_mutex , mutex , spinlock , rw_spinlock or proclock . entry In combination with {locations, true} this option prints the lock operations source file and line number entry-points along with statistics for each entry. tries Number of acquisitions of this lock. colls Number of collisions when a thread tried to acquire this lock. This is when a trylock is EBUSY, a write try on read held rw_lock, a try read on write held rw_lock, a thread tries to lock an already locked lock. (Internal states supervises this). ratio The ratio between the number of collisions and the number of tries (acquisitions) in percentage. time Accumulated waiting time for this lock. This could be greater than actual wall clock time, it is accumulated for all threads. Trylock conflicts does not accumulate time. duration Percentage of accumulated waiting time of wall clock time. This percentage can be higher than 100% since accumulated time is from all threads. Default: [name,id,tries,colls,ratio,time,duration] {reverse, boolean()} Reverses the order of sorting. Default: false {sort, Sort} Column sorting orders. Default: time {thresholds, Thresholds} Filtering thresholds. Anything values above the threshold value are passed through. Default: [{tries, 0}, {colls, 0}, {time, 0}]","ref":"lcnt.html#inspect/2","title":"lcnt.inspect/2","type":"function"},{"doc":"Restores previously saved data to the server.","ref":"lcnt.html#load/1","title":"lcnt.load/1","type":"function"},{"doc":"Same as locations([]) .","ref":"lcnt.html#locations/0","title":"lcnt.locations/0","type":"function"},{"doc":"Prints a list of internal lock counters by source code locations. For option description, see lcnt:inspect/2 .","ref":"lcnt.html#locations/1","title":"lcnt.locations/1","type":"function"},{"doc":"Same as pid(node(), Id, Serial) .","ref":"lcnt.html#pid/2","title":"lcnt.pid/2","type":"function"},{"doc":"Creates a process id with creation 0.","ref":"lcnt.html#pid/3","title":"lcnt.pid/3","type":"function"},{"doc":"Same as port(node(), Id) .","ref":"lcnt.html#port/1","title":"lcnt.port/1","type":"function"},{"doc":"Creates a port id with creation 0.","ref":"lcnt.html#port/2","title":"lcnt.port/2","type":"function"},{"doc":"Same as rt_clear(node()) .","ref":"lcnt.html#rt_clear/0","title":"lcnt.rt_clear/0","type":"function"},{"doc":"Clear the internal counters. Same as lcnt:clear(Node) .","ref":"lcnt.html#rt_clear/1","title":"lcnt.rt_clear/1","type":"function"},{"doc":"Same as rt_collect(node()) .","ref":"lcnt.html#rt_collect/0","title":"lcnt.rt_collect/0","type":"function"},{"doc":"Returns a list of raw lock counter data.","ref":"lcnt.html#rt_collect/1","title":"lcnt.rt_collect/1","type":"function"},{"doc":"Same as rt_mask(node()) .","ref":"lcnt.html#rt_mask/0","title":"lcnt.rt_mask/0","type":"function"},{"doc":"Refer to rt_mask/2 . for a list of valid categories. All categories are enabled by default.","ref":"lcnt.html#rt_mask/1","title":"lcnt.rt_mask/1","type":"function"},{"doc":"Same as rt_mask(node(), Categories) .","ref":"lcnt.html#rt_mask/1","title":"lcnt.rt_mask/1","type":"function"},{"doc":"Sets the lock category mask to the given categories. This will fail if the copy_save option is enabled; see lcnt:rt_opt/2 . Valid categories are: allocator db (ETS tables) debug distribution generic io process scheduler This list is subject to change at any time, as is the category any given lock may belong to.","ref":"lcnt.html#rt_mask/2","title":"lcnt.rt_mask/2","type":"function"},{"doc":"Same as rt_opt(node(), {Type, Value}) .","ref":"lcnt.html#rt_opt/1","title":"lcnt.rt_opt/1","type":"function"},{"doc":"Option description: {copy_save, boolean()} Retains the statistics of destroyed locks. Default: false This option will use a lot of memory when enabled, which must be reclaimed with lcnt:rt_clear . Note that it makes no distinction between locks that were destroyed and locks for which counting was disabled, so enabling this option will disable changes to the lock category mask. {process_locks, boolean()} Profile process locks, equal to adding process to the lock category mask; see lcnt:rt_mask/2 Default: true","ref":"lcnt.html#rt_opt/2","title":"lcnt.rt_opt/2","type":"function"},{"doc":"Saves the collected data to file.","ref":"lcnt.html#save/1","title":"lcnt.save/1","type":"function"},{"doc":"Starts the lock profiler server. The server only act as a medium for the user and performs filtering and printing of data collected by lcnt:collect/1 .","ref":"lcnt.html#start/0","title":"lcnt.start/0","type":"function"},{"doc":"Stops the lock profiler server.","ref":"lcnt.html#stop/0","title":"lcnt.stop/0","type":"function"},{"doc":"Swaps places on Name and Id space for ports and processes.","ref":"lcnt.html#swap_pid_keys/0","title":"lcnt.swap_pid_keys/0","type":"function"},{"doc":"The module make provides a set of functions similar to the UNIX type Make functions. Emakefile make:all/0,1 and make:files/1,2 first looks for {emake, Emake} in options, then in the current working directory for a file named Emakefile . If present Emake should contain elements like this: Modules. {Modules,Options}. Modules is an atom or a list of atoms. It can be a module name, e.g. file1 a module name in another directory, e.g. '../foo/file3' a set of modules specified with a wildcards, e.g. 'file*' a wildcard indicating all modules in current directory, i.e. '*' a list of any of the above, e.g. ['file*','../foo/file3','File4'] Options is a list of compiler options. Emakefile is read from top to bottom. If a module matches more than one entry, the first match is valid. For example, the following Emakefile means that file1 shall be compiled with the options [debug_info,{i,&quot;../foo&quot;}] , while all other files in the current directory shall be compiled with only the debug_info flag. {'file1',[debug_info,{i,&quot;../foo&quot;}]}. {'*',[debug_info]}. See Also compile(3)","ref":"make.html","title":"make","type":"module"},{"doc":"This function determines the set of modules to compile and the compile options to use, by first looking for the emake make option, if not present reads the configuration from a file named Emakefile (see below). If no such file is found, the set of modules to compile defaults to all modules in the current working directory. Traversing the set of modules, it then recompiles every module for which at least one of the following conditions apply: there is no object file, or the source file has been modified since it was last compiled, or, an include file has been modified since the source file was last compiled. As a side effect, the function prints the name of each module it tries to compile. If compilation fails for a module, the make procedure stops and error is returned. Options is a list of make- and compiler options. The following make options exist: noexec No execution mode. Just prints the name of each module that needs to be compiled. load Load mode. Loads all recompiled modules. netload Net load mode. Loads all recompiled modules on all known nodes. {emake, Emake} Rather than reading the Emakefile specify configuration explicitly. All items in Options that are not make options are assumed to be compiler options and are passed as-is to compile:file/2 . Options defaults to [] .","ref":"make.html#all/0","title":"make.all/0","type":"function"},{"doc":"","ref":"make.html#all/1","title":"make.all/1","type":"function"},{"doc":"files/1,2 does exactly the same thing as all/0,1 but for the specified ModFiles , which is a list of module or file names. The file extension .erl may be omitted. The Emakefile (if it exists) in the current directory is searched for compiler options for each module. If a given module does not exist in Emakefile or if Emakefile does not exist, the module is still compiled.","ref":"make.html#files/1","title":"make.files/1","type":"function"},{"doc":"","ref":"make.html#files/2","title":"make.files/2","type":"function"},{"doc":"A TAGS file is used by Emacs to find function and variable definitions in any source file in large projects. This module can generate a TAGS file from Erlang source files. It recognises functions, records, and macro definitions. OPTIONS The functions above have an optional argument, Options . It is a list which can contain the following elements: {outfile, NameOfTAGSFile} Create a TAGS file named NameOfTAGSFile . {outdir, NameOfDirectory} Create a file named TAGS in the directory NameOfDirectory . The default behaviour is to create a file named TAGS in the current directory. Examples tags:root([{outfile, &quot;root.TAGS&quot;}]). This command will create a file named root.TAGS in the current directory. The file will contain references to all Erlang source files in the Erlang distribution. tags:files([&quot;foo.erl&quot;, &quot;bar.erl&quot;, &quot;baz.erl&quot;], [{outdir, &quot;../projectdir&quot;}]). Here we create file named TAGS placed it in the directory ../projectdir . The file contains information about the functions, records, and macro definitions of the three files. SEE ALSO Richard M. Stallman. GNU Emacs Manual, chapter &quot;Editing Programs&quot;, section &quot;Tag Tables&quot;. Free Software Foundation, 1995. Anders Lindgren. The Erlang editing mode for Emacs. Ericsson, 1998.","ref":"tags.html","title":"tags","type":"module"},{"doc":"Create a TAGS file for all files in directory Dir .","ref":"tags.html#dir/1","title":"tags.dir/1","type":"function"},{"doc":"","ref":"tags.html#dir/2","title":"tags.dir/2","type":"function"},{"doc":"Create a TAGS file for all files in any directory in DirList .","ref":"tags.html#dirs/1","title":"tags.dirs/1","type":"function"},{"doc":"","ref":"tags.html#dirs/2","title":"tags.dirs/2","type":"function"},{"doc":"Create a TAGS file for the file File .","ref":"tags.html#file/1","title":"tags.file/1","type":"function"},{"doc":"","ref":"tags.html#file/2","title":"tags.file/2","type":"function"},{"doc":"Create a TAGS file for the files in the list FileList .","ref":"tags.html#files/1","title":"tags.files/1","type":"function"},{"doc":"","ref":"tags.html#files/2","title":"tags.files/2","type":"function"},{"doc":"Create a TAGS file covering all files in the Erlang distribution.","ref":"tags.html#root/0","title":"tags.root/0","type":"function"},{"doc":"","ref":"tags.html#root/1","title":"tags.root/1","type":"function"},{"doc":"Descend recursively down the directory Dir and create a TAGS file based on all files found.","ref":"tags.html#subdir/1","title":"tags.subdir/1","type":"function"},{"doc":"","ref":"tags.html#subdir/2","title":"tags.subdir/2","type":"function"},{"doc":"Descend recursively down all the directories in DirList and create a TAGS file based on all files found.","ref":"tags.html#subdirs/1","title":"tags.subdirs/1","type":"function"},{"doc":"","ref":"tags.html#subdirs/2","title":"tags.subdirs/2","type":"function"},{"doc":"Xref is a cross reference tool that can be used for finding dependencies between functions, modules, applications and releases. Calls between functions are either local calls like f() , or external calls like m:f() . Module data , which are extracted from BEAM files, include local functions, exported functions, local calls and external calls. By default, calls to built-in functions (BIF) are ignored, but if the option builtins , accepted by some of this module's functions, is set to true , calls to BIFs are included as well. It is the analyzing OTP version that decides what functions are BIFs. Functional objects are assumed to be called where they are created (and nowhere else). Unresolved calls are calls to apply or spawn with variable module, variable function, or variable arguments. Examples are M:F(a) , apply(M, f, [a]) , and spawn(m, f(), Args) . Unresolved calls are represented by calls where variable modules have been replaced with the atom '$M_EXPR' , variable functions have been replaced with the atom '$F_EXPR' , and variable number of arguments have been replaced with the number -1 . The above mentioned examples are represented by calls to '$M_EXPR':'$F_EXPR'/1 , '$M_EXPR':f/1 , and m:'$F_EXPR'/-1 . The unresolved calls are a subset of the external calls. Unresolved calls make module data incomplete, which implies that the results of analyses may be invalid. Applications are collections of modules. The modules' BEAM files are located in the ebin subdirectory of the application directory. The name of the application directory determines the name and version of the application. Releases are collections of applications located in the lib subdirectory of the release directory. There is more to read about applications and releases in the Design Principles book. Xref servers are identified by names, supplied when creating new servers. Each Xref server holds a set of releases, a set of applications, and a set of modules with module data. Xref servers are independent of each other, and all analyses are evaluated in the context of one single Xref server (exceptions are the functions m/1 and d/1 which do not use servers at all). The mode of an Xref server determines what module data are extracted from BEAM files as modules are added to the server. Starting with R7, BEAM files compiled with the option debug_info contain so called debug information, which is an abstract representation of the code. In functions mode, which is the default mode, function calls and line numbers are extracted from debug information. In modules mode, debug information is ignored if present, but dependencies between modules are extracted from other parts of the BEAM files. The modules mode is significantly less time and space consuming than the functions mode, but the analyses that can be done are limited. An analyzed module is a module that has been added to an Xref server together with its module data. A library module is a module located in some directory mentioned in the library path . A library module is said to be used if some of its exported functions are used by some analyzed module. An unknown module is a module that is neither an analyzed module nor a library module, but whose exported functions are used by some analyzed module. An unknown function is a used function that is neither local or exported by any analyzed module nor exported by any library module. An undefined function is an externally used function that is not exported by any analyzed module or library module. With this notion, a local function can be an undefined function, namely if it is externally used from some module. All unknown functions are also undefined functions; there is a figure in the User's Guide that illustrates this relationship. Starting with R9C, the module attribute tag deprecated can be used to inform Xref about deprecated functions and optionally when functions are planned to be removed. A few examples show the idea: -deprecated({f,1}). The exported function f/1 is deprecated. Nothing is said whether f/1 will be removed or not. -deprecated({f,1,&quot;Use g/1 instead&quot;}). As above but with a descriptive string. The string is currently unused by xref but other tools can make use of it. -deprecated({f,'_'}). All exported functions f/0 , f/1 and so on are deprecated. -deprecated(module). All exported functions in the module are deprecated. Equivalent to -deprecated({'_','_'}). . -deprecated([{g,1,next_version}]). The function g/1 is deprecated and will be removed in next version. -deprecated([{g,2,next_major_release}]). The function g/2 is deprecated and will be removed in next major release. -deprecated([{g,3,eventually}]). The function g/3 is deprecated and will eventually be removed. -deprecated({'_','_',eventually}). All exported functions in the module are deprecated and will eventually be removed. Before any analysis can take place, module data must be set up . For instance, the cross reference and the unknown functions are computed when all module data are known. The functions that need complete data ( analyze , q , variables ) take care of setting up data automatically. Module data need to be set up (again) after calls to any of the add , replace , remove , set_library_path or update functions. The result of setting up module data is the Call Graph . A (directed) graph consists of a set of vertices and a set of (directed) edges. The edges represent calls (From, To) between functions, modules, applications or releases. From is said to call To, and To is said to be used by From. The vertices of the Call Graph are the functions of all module data: local and exported functions of analyzed modules; used BIFs; used exported functions of library modules; and unknown functions. The functions module_info/0,1 added by the compiler are included among the exported functions, but only when called from some module. The edges are the function calls of all module data. A consequence of the edges being a set is that there is only one edge if a function is locally or externally used several times on one and the same line of code. The Call Graph is represented by Erlang terms (the sets are lists), which is suitable for many analyses. But for analyses that look at chains of calls, a list representation is much too slow. Instead the representation offered by the digraph module is used. The translation of the list representation of the Call Graph - or a subgraph thereof - to the digraph representation does not come for free, so the language used for expressing queries to be described below has a special operator for this task and a possibility to save the digraph representation for subsequent analyses. In addition to the Call Graph there is a graph called the Inter Call Graph . This is a graph of calls (From, To) such that there is a chain of calls from From to To in the Call Graph, and every From and To is an exported function or an unused local function. The vertices are the same as for the Call Graph. Calls between modules, applications and releases are also directed graphs. The types of the vertices and edges of these graphs are (ranging from the most special to the most general): Fun for functions; Mod for modules; App for applications; and Rel for releases. The following paragraphs will describe the different constructs of the language used for selecting and analyzing parts of the graphs, beginning with the constants : Expression ::= Constants Constants ::= Consts | Consts : Type | RegExpr Consts ::= Constant | [ Constant ,  ... ] | { Constant ,  ... } Constant ::= Call | Const Call ::= FunSpec  -&gt;  FunSpec | { MFA ,  MFA } | AtomConst  -&gt;  AtomConst | { AtomConst ,  AtomConst } Const ::= AtomConst | FunSpec | MFA AtomConst ::= Application | Module | Release FunSpec ::= Module : Function / Arity MFA ::= { Module ,  Function ,  Arity } RegExpr ::= RegString : Type | RegFunc | RegFunc : Type RegFunc ::= RegModule : RegFunction / RegArity RegModule ::= RegAtom RegFunction ::= RegAtom RegArity ::= RegString | Number | _ | -1 RegAtom ::= RegString | Atom | _ RegString ::= - a regular expression, as described in the re module, enclosed in double quotes - Type ::= Fun | Mod | App | Rel Function ::= Atom Application ::= Atom Module ::= Atom Release ::= Atom Arity ::= Number | -1 Atom ::= - same as Erlang atoms - Number ::= - same as non-negative Erlang integers - Examples of constants are: kernel , kernel-&gt;stdlib , [kernel, sasl] , [pg -&gt; mnesia, {tv, mnesia}] : Mod . It is an error if an instance of Const does not match any vertex of any graph. If there are more than one vertex matching an untyped instance of AtomConst , then the one of the most general type is chosen. A list of constants is interpreted as a set of constants, all of the same type. A tuple of constants constitute a chain of calls (which may, but does not have to, correspond to an actual chain of calls of some graph). Assigning a type to a list or tuple of Constant is equivalent to assigning the type to each Constant . Regular expressions are used as a means to select some of the vertices of a graph. A RegExpr consisting of a RegString and a type - an example is &quot;xref_.*&quot; : Mod - is interpreted as those modules (or applications or releases, depending on the type) that match the expression. Similarly, a RegFunc is interpreted as those vertices of the Call Graph that match the expression. An example is &quot;xref_.*&quot;:&quot;add_.*&quot;/&quot;(2|3)&quot; , which matches all add functions of arity two or three of any of the xref modules. Another example, one that matches all functions of arity 10 or more: _:_/&quot;[1-9].+&quot; . Here _ is an abbreviation for &quot;.*&quot; , that is, the regular expression that matches anything. The syntax of variables is simple: Expression ::= Variable Variable ::= - same as Erlang variables - There are two kinds of variables: predefined variables and user variables. Predefined variables hold set up module data, and cannot be assigned to but only used in queries. User variables on the other hand can be assigned to, and are typically used for temporary results while evaluating a query, and for keeping results of queries for use in subsequent queries. The predefined variables are (variables marked with (*) are available in functions mode only): E Call Graph Edges (*). V Call Graph Vertices (*). M Modules. All modules: analyzed modules, used library modules, and unknown modules. A Applications. R Releases. ME Module Edges. All module calls. AE Application Edges. All application calls. RE Release Edges. All release calls. L Local Functions (*). All local functions of analyzed modules. X Exported Functions. All exported functions of analyzed modules and all used exported functions of library modules. F Functions (*). B Used BIFs. B is empty if builtins is false for all analyzed modules. U Unknown Functions. UU Unused Functions (*). All local and exported functions of analyzed modules that have not been used. XU Externally Used Functions. Functions of all modules - including local functions - that have been used in some external call. LU Locally Used Functions (*). Functions of all modules that have been used in some local call. OL Functions with an attribute tag on_load (*). LC Local Calls (*). XC External Calls (*). AM Analyzed Modules. UM Unknown Modules. LM Used Library Modules. UC Unresolved Calls. Empty in modules mode. EE Inter Call Graph Edges (*). DF Deprecated Functions. All deprecated exported functions and all used deprecated BIFs. DF_1 Deprecated Functions. All deprecated functions to be removed in next version. DF_2 Deprecated Functions. All deprecated functions to be removed in next version or next major release. DF_3 Deprecated Functions. All deprecated functions to be removed in next version, next major release, or later. These are a few facts about the predefined variables (the set operators + (union) and - (difference) as well as the cast operator ( Type ) are described below): F is equal to L + X . V is equal to X + L + B + U , where X , L , B and U are pairwise disjoint (that is, have no elements in common). UU is equal to V - (XU + LU) , where LU and XU may have elements in common. Put in another way: V is equal to UU + XU + LU . OL is a subset of F . E is equal to LC + XC . Note that LC and XC may have elements in common, namely if some function is locally and externally used from one and the same function. U is a subset of XU . B is a subset of XU . LU is equal to range LC . XU is equal to range XC . LU is a subset of F . UU is a subset of F . range UC is a subset of U . M is equal to AM + LM + UM , where AM , LM and UM are pairwise disjoint. ME is equal to (Mod) E . AE is equal to (App) E . RE is equal to (Rel) E . (Mod) V is a subset of M . Equality holds if all analyzed modules have some local, exported, or unknown function. (App) M is a subset of A . Equality holds if all applications have some module. (Rel) A is a subset of R . Equality holds if all releases have some application. DF_1 is a subset of DF_2 . DF_2 is a subset of DF_3 . DF_3 is a subset of DF . DF is a subset of X + B . An important notion is that of conversion of expressions. The syntax of a cast expression is: Expression ::= ( Type ) Expression The interpretation of the cast operator depends on the named type Type , the type of Expression , and the structure of the elements of the interpretation of Expression . If the named type is equal to the expression type, no conversion is done. Otherwise, the conversion is done one step at a time; (Fun) (App) RE , for instance, is equivalent to (Fun) (Mod) (App) RE . Now assume that the interpretation of Expression is a set of constants (functions, modules, applications or releases). If the named type is more general than the expression type, say Mod and Fun respectively, then the interpretation of the cast expression is the set of modules that have at least one of their functions mentioned in the interpretation of the expression. If the named type is more special than the expression type, say Fun and Mod , then the interpretation is the set of all the functions of the modules (in modules mode, the conversion is partial since the local functions are not known). The conversions to and from applications and releases work analogously. For instance, (App) &quot;xref_.*&quot; : Mod returns all applications containing at least one module such that xref_ is a prefix of the module name. Now assume that the interpretation of Expression is a set of calls. If the named type is more general than the expression type, say Mod and Fun respectively, then the interpretation of the cast expression is the set of calls (M1, M2) such that the interpretation of the expression contains a call from some function of M1 to some function of M2. If the named type is more special than the expression type, say Fun and Mod , then the interpretation is the set of all function calls (F1, F2) such that the interpretation of the expression contains a call (M1, M2) and F1 is a function of M1 and F2 is a function of M2 (in modules mode, there are no functions calls, so a cast to Fun always yields an empty set). Again, the conversions to and from applications and releases work analogously. The interpretation of constants and variables are sets, and those sets can be used as the basis for forming new sets by the application of set operators . The syntax: Expression ::= Expression BinarySetOp Expression BinarySetOp ::= + | * | - + , * and - are interpreted as union, intersection and difference respectively: the union of two sets contains the elements of both sets; the intersection of two sets contains the elements common to both sets; and the difference of two sets contains the elements of the first set that are not members of the second set. The elements of the two sets must be of the same structure; for instance, a function call cannot be combined with a function. But if a cast operator can make the elements compatible, then the more general elements are converted to the less general element type. For instance, M + F is equivalent to (Fun) M + F , and E - AE is equivalent to E - (Fun) AE . One more example: X * xref : Mod is interpreted as the set of functions exported by the module xref ; xref : Mod is converted to the more special type of X ( Fun , that is) yielding all functions of xref , and the intersection with X (all functions exported by analyzed modules and library modules) is interpreted as those functions that are exported by some module and functions of xref . There are also unary set operators: Expression ::= UnarySetOp Expression UnarySetOp ::= domain | range | strict Recall that a call is a pair (From, To). domain applied to a set of calls is interpreted as the set of all vertices From, and range as the set of all vertices To. The interpretation of the strict operator is the operand with all calls on the form (A, A) removed. The interpretation of the restriction operators is a subset of the first operand, a set of calls. The second operand, a set of vertices, is converted to the type of the first operand. The syntax of the restriction operators: Expression ::= Expression RestrOp Expression RestrOp ::= | RestrOp ::= || RestrOp ::= ||| The interpretation in some detail for the three operators: | The subset of calls from any of the vertices. || The subset of calls to any of the vertices. ||| The subset of calls to and from any of the vertices. For all sets of calls CS and all sets of vertices VS , CS ||| VS  is equivalent to CS | VS * CS || VS . Two functions (modules, applications, releases) belong to the same strongly connected component if they call each other (in)directly. The interpretation of the components operator is the set of strongly connected components of a set of calls. The condensation of a set of calls is a new set of calls between the strongly connected components such that there is an edge between two components if there is some constant of the first component that calls some constant of the second component. The interpretation of the of operator is a chain of calls of the second operand (a set of calls) that passes throw all of the vertices of the first operand (a tuple of constants), in the given order. The second operand is converted to the type of the first operand. For instance, the of operator can be used for finding out whether a function calls another function indirectly, and the chain of calls demonstrates how. The syntax of the graph analyzing operators: Expression ::= Expression BinaryGraphOp Expression Expression ::= UnaryGraphOp Expression UnaryGraphOp ::= components | condensation BinaryGraphOp ::= of As was mentioned before, the graph analyses operate on the digraph representation of graphs. By default, the digraph representation is created when needed (and deleted when no longer used), but it can also be created explicitly by use of the closure operator: Expression ::= ClosureOp Expression ClosureOp ::= closure The interpretation of the closure operator is the transitive closure of the operand. The restriction operators are defined for closures as well; closure E | xref : Mod is interpreted as the direct or indirect function calls from the xref module, while the interpretation of E | xref : Mod is the set of direct calls from xref . If some graph is to be used in several graph analyses, it saves time to assign the digraph representation of the graph to a user variable, and then make sure that every graph analysis operates on that variable instead of the list representation of the graph. The lines where functions are defined (more precisely: where the first clause begins) and the lines where functions are used are available in functions mode. The line numbers refer to the files where the functions are defined. This holds also for files included with the -include and -include_lib directives, which may result in functions defined apparently in the same line. The line operators are used for assigning line numbers to functions and for assigning sets of line numbers to function calls. The syntax is similar to the one of the cast operator: Expression ::= ( LineOp ) Expression Expression ::= ( XLineOp ) Expression LineOp ::= Lin | ELin | LLin | XLin XLineOp ::= XXL The interpretation of the Lin operator applied to a set of functions assigns to each function the line number where the function is defined. Unknown functions and functions of library modules are assigned the number 0. The interpretation of some LineOp operator applied to a set of function calls assigns to each call the set of line numbers where the first function calls the second function. Not all calls are assigned line numbers by all operators: the Lin operator is defined for Call Graph Edges; the LLin operator is defined for Local Calls. the XLin operator is defined for External Calls. the ELin operator is defined for Inter Call Graph Edges. The Lin ( LLin , XLin ) operator assigns the lines where calls (local calls, external calls) are made. The ELin operator assigns to each call (From, To), for which it is defined, every line L such that there is a chain of calls from From to To beginning with a call on line L. The XXL operator is defined for the interpretation of any of the LineOp operators applied to a set of function calls. The result is that of replacing the function call with a line numbered function call, that is, each of the two functions of the call is replaced by a pair of the function and the line where the function is defined. The effect of the XXL operator can be undone by the LineOp operators. For instance, (Lin) (XXL) (Lin) E is equivalent to (Lin) E . The + , - , * and # operators are defined for line number expressions, provided the operands are compatible. The LineOp operators are also defined for modules, applications, and releases; the operand is implicitly converted to functions. Similarly, the cast operator is defined for the interpretation of the LineOp operators. The interpretation of the counting operator is the number of elements of a set. The operator is undefined for closures. The + , - and * operators are interpreted as the obvious arithmetical operators when applied to numbers. The syntax of the counting operator: Expression ::= CountOp Expression CountOp ::= # All binary operators are left associative; for instance, A | B  || C is equivalent to (A | B) || C . The following is a list of all operators, in increasing order of precedence : + , - * # | , || , ||| of ( Type ) closure , components , condensation , domain , range , strict Parentheses are used for grouping, either to make an expression more readable or to override the default precedence of operators: Expression ::= ( Expression ) A query is a non-empty sequence of statements. A statement is either an assignment of a user variable or an expression. The value of an assignment is the value of the right hand side expression. It makes no sense to put a plain expression anywhere else but last in queries. The syntax of queries is summarized by these productions: Query ::= Statement ,  ... Statement ::= Assignment | Expression Assignment ::= Variable := Expression | Variable = Expression A variable cannot be assigned a new value unless first removed. Variables assigned to by the = operator are removed at the end of the query, while variables assigned to by the := operator can only be removed by calls to forget . There are no user variables when module data need to be set up again; if any of the functions that make it necessary to set up module data again is called, all user variables are forgotten. See Also beam_lib(3) , digraph(3) , digraph_utils(3) , re(3) , TOOLS User's Guide","ref":"xref.html","title":"xref","type":"module"},{"doc":"Adds an application, the modules of the application and module data of the modules to an Xref server . The modules will be members of the application. The default is to use the base name of the directory with the version removed as application name, but this can be overridden by the name option. Returns the name of the application. If the given directory has a subdirectory named ebin , modules (BEAM files) are searched for in that directory, otherwise modules are searched for in the given directory. If the mode of the Xref server is functions , BEAM files that contain no debug information are ignored.","ref":"xref.html#add_application/2","title":"xref.add_application/2","type":"function"},{"doc":"","ref":"xref.html#add_application/3","title":"xref.add_application/3","type":"function"},{"doc":"Adds the modules found in the given directory and the modules' data to an Xref server . The default is not to examine subdirectories, but if the option recurse has the value true , modules are searched for in subdirectories on all levels as well as in the given directory. Returns a sorted list of the names of the added modules. The modules added will not be members of any applications. If the mode of the Xref server is functions , BEAM files that contain no debug information are ignored.","ref":"xref.html#add_directory/2","title":"xref.add_directory/2","type":"function"},{"doc":"","ref":"xref.html#add_directory/3","title":"xref.add_directory/3","type":"function"},{"doc":"Adds a module and its module data to an Xref server . The module will not be member of any application. Returns the name of the module. If the mode of the Xref server is functions , and the BEAM file contains no debug information , the error message no_debug_info is returned.","ref":"xref.html#add_module/2","title":"xref.add_module/2","type":"function"},{"doc":"","ref":"xref.html#add_module/3","title":"xref.add_module/3","type":"function"},{"doc":"Adds a release, the applications of the release, the modules of the applications, and module data of the modules to an Xref server . The applications will be members of the release, and the modules will be members of the applications. The default is to use the base name of the directory as release name, but this can be overridden by the name option. Returns the name of the release. If the given directory has a subdirectory named lib , the directories in that directory are assumed to be application directories, otherwise all subdirectories of the given directory are assumed to be application directories. If there are several versions of some application, the one with the highest version is chosen. If the mode of the Xref server is functions , BEAM files that contain no debug information are ignored.","ref":"xref.html#add_release/2","title":"xref.add_release/2","type":"function"},{"doc":"","ref":"xref.html#add_release/3","title":"xref.add_release/3","type":"function"},{"doc":"Evaluates a predefined analysis. Returns a sorted list without duplicates of call() or constant() , depending on the chosen analysis. The predefined analyses, which operate on all analyzed modules , are (analyses marked with (*) are available in functions mode only): undefined_function_calls (*) Returns a list of calls to undefined functions . undefined_functions Returns a list of undefined functions . locals_not_used (*) Returns a list of local functions that have not been locally used. exports_not_used Returns a list of exported functions that have not been externally used. Note that in modules mode, M:behaviour_info/1 is never reported as unused. deprecated_function_calls (*) Returns a list of external calls to deprecated functions . {deprecated_function_calls, DeprFlag} (*) Returns a list of external calls to deprecated functions. If DeprFlag is equal to next_version , calls to functions to be removed in next version are returned. If DeprFlag is equal to next_major_release , calls to functions to be removed in next major release are returned as well as calls to functions to be removed in next version. Finally, if DeprFlag is equal to eventually , all calls to functions to be removed are returned, including calls to functions to be removed in next version or next major release. deprecated_functions Returns a list of externally used deprecated functions. {deprecated_functions, DeprFlag} Returns a list of externally used deprecated functions. If DeprFlag is equal to next_version , functions to be removed in next version are returned. If DeprFlag is equal to next_major_release , functions to be removed in next major release are returned as well as functions to be removed in next version. Finally, if DeprFlag is equal to eventually , all functions to be removed are returned, including functions to be removed in next version or next major release. {call, FuncSpec} (*) Returns a list of functions called by some of the given functions. {use, FuncSpec} (*) Returns a list of functions that use some of the given functions. {module_call, ModSpec} Returns a list of modules called by some of the given modules. {module_use, ModSpec} Returns a list of modules that use some of the given modules. {application_call, AppSpec} Returns a list of applications called by some of the given applications. {application_use, AppSpec} Returns a list of applications that use some of the given applications. {release_call, RelSpec} Returns a list of releases called by some of the given releases. {release_use, RelSpec} Returns a list of releases that use some of the given releases.","ref":"xref.html#analyze/2","title":"xref.analyze/2","type":"function"},{"doc":"","ref":"xref.html#analyze/3","title":"xref.analyze/3","type":"function"},{"doc":"The modules found in the given directory are checked for calls to deprecated functions , calls to undefined functions , and for unused local functions. The code path is used as library path . If some of the found BEAM files contain debug information , then those modules are checked and a list of tuples is returned. The first element of each tuple is one of: deprecated , the second element is a sorted list of calls to deprecated functions; undefined , the second element is a sorted list of calls to undefined functions; unused , the second element is a sorted list of unused local functions. If no BEAM file contains debug information, then a list of tuples is returned. The first element of each tuple is one of: deprecated , the second element is a sorted list of externally used deprecated functions; undefined , the second element is a sorted list of undefined functions.","ref":"xref.html#d/1","title":"xref.d/1","type":"function"},{"doc":"forget/1 and forget/2 remove all or some of the user variables of an Xref server .","ref":"xref.html#forget/1","title":"xref.forget/1","type":"function"},{"doc":"","ref":"xref.html#forget/2","title":"xref.forget/2","type":"function"},{"doc":"Given the error returned by any function of this module, the function format_error returns a descriptive string of the error in English. For file errors, the function file:format_error/1 is called.","ref":"xref.html#format_error/1","title":"xref.format_error/1","type":"function"},{"doc":"Returns the default values of one or more options.","ref":"xref.html#get_default/1","title":"xref.get_default/1","type":"function"},{"doc":"","ref":"xref.html#get_default/2","title":"xref.get_default/2","type":"function"},{"doc":"Returns the library path .","ref":"xref.html#get_library_path/1","title":"xref.get_library_path/1","type":"function"},{"doc":"The info functions return information as a list of pairs {Tag, term()} in some order about the state and the module data of an Xref server . info/1 returns information with the following tags (tags marked with (*) are available in functions mode only): library_path , the library path ; mode , the mode ; no_releases , number of releases; no_applications , total number of applications (of all releases); no_analyzed_modules , total number of analyzed modules ; no_calls (*), total number of calls (in all modules), regarding instances of one function call in different lines as separate calls; no_function_calls (*), total number of local calls , resolved external calls and unresolved calls ; no_functions (*), total number of local and exported functions; no_inter_function_calls (*), total number of calls of the Inter Call Graph . info/2 and info/3 return information about all or some of the analyzed modules, applications, releases or library modules of an Xref server. The following information is returned for every analyzed module: application , an empty list if the module does not belong to any application, otherwise a list of the application name; builtins , whether calls to BIFs are included in the module's data; directory , the directory where the module's BEAM file is located; no_calls (*), number of calls, regarding instances of one function call in different lines as separate calls; no_function_calls (*), number of local calls, resolved external calls and unresolved calls; no_functions (*), number of local and exported functions; no_inter_function_calls (*), number of calls of the Inter Call Graph; The following information is returned for every application: directory , the directory where the modules' BEAM files are located; no_analyzed_modules , number of analyzed modules; no_calls (*), number of calls of the application's modules, regarding instances of one function call in different lines as separate calls; no_function_calls (*), number of local calls, resolved external calls and unresolved calls of the application's modules; no_functions (*), number of local and exported functions of the application's modules; no_inter_function_calls (*), number of calls of the Inter Call Graph of the application's modules; release , an empty list if the application does not belong to any release, otherwise a list of the release name; version , the application's version as a list of numbers. For instance, the directory &quot;kernel-2.6&quot; results in the application name kernel and the application version [2,6]; &quot;kernel&quot; yields the name kernel and the version []. The following information is returned for every release: directory , the release directory; no_analyzed_modules , number of analyzed modules; no_applications , number of applications; no_calls (*), number of calls of the release's modules, regarding instances of one function call in different lines as separate calls; no_function_calls (*), number of local calls, resolved external calls and unresolved calls of the release's modules; no_functions (*), number of local and exported functions of the release's modules; no_inter_function_calls (*), number of calls of the Inter Call Graph of the release's modules. The following information is returned for every library module: directory , the directory where the library module's BEAM file is located. For every number of calls, functions etc. returned by the no_ tags, there is a query returning the same number. Listed below are examples of such queries. Some of the queries return the sum of a two or more of the no_ tags numbers. mod ( app , rel ) refers to any module (application, release). no_analyzed_modules &quot;# AM&quot; (info/1) &quot;# (Mod) app:App&quot; (application) &quot;# (Mod) rel:Rel&quot; (release) no_applications &quot;# A&quot; (info/1) no_calls . The sum of the number of resolved and unresolved calls: &quot;# (XLin) E + # (LLin) E&quot; (info/1) &quot;T = E | mod:Mod, # (LLin) T + # (XLin) T&quot; (module) &quot;T = E | app:App, # (LLin) T + # (XLin) T&quot; (application) &quot;T = E | rel:Rel, # (LLin) T + # (XLin) T&quot; (release) no_functions . Functions in library modules and the functions module_info/0,1 are not counted by info . Assuming that &quot;Extra := _:module_info/\\&quot;(0|1)\\&quot; + LM&quot; has been evaluated, the sum of the number of local and exported functions are: &quot;# (F - Extra)&quot; (info/1) &quot;# (F * mod:Mod - Extra)&quot; (module) &quot;# (F * app:App - Extra)&quot; (application) &quot;# (F * rel:Rel - Extra)&quot; (release) no_function_calls . The sum of the number of local calls, resolved external calls and unresolved calls: &quot;# LC + # XC&quot; (info/1) &quot;# LC | mod:Mod + # XC | mod:Mod&quot; (module) &quot;# LC | app:App + # XC | app:App&quot; (application) &quot;# LC | rel:Rel + # XC | mod:Rel&quot; (release) no_inter_function_calls &quot;# EE&quot; (info/1) &quot;# EE | mod:Mod&quot; (module) &quot;# EE | app:App&quot; (application) &quot;# EE | rel:Rel&quot; (release) no_releases &quot;# R&quot; (info/1)","ref":"xref.html#info/1","title":"xref.info/1","type":"function"},{"doc":"","ref":"xref.html#info/2","title":"xref.info/2","type":"function"},{"doc":"","ref":"xref.html#info/3","title":"xref.info/3","type":"function"},{"doc":"The given BEAM file (with or without the .beam extension) or the file found by calling code:which(Module) is checked for calls to deprecated functions , calls to undefined functions , and for unused local functions. The code path is used as library path . If the BEAM file contains debug information , then a list of tuples is returned. The first element of each tuple is one of: deprecated , the second element is a sorted list of calls to deprecated functions; undefined , the second element is a sorted list of calls to undefined functions; unused , the second element is a sorted list of unused local functions. If the BEAM file does not contain debug information, then a list of tuples is returned. The first element of each tuple is one of: deprecated , the second element is a sorted list of externally used deprecated functions; undefined , the second element is a sorted list of undefined functions.","ref":"xref.html#m/1","title":"xref.m/1","type":"function"},{"doc":"Evaluates a query in the context of an Xref server , and returns the value of the last statement. The syntax of the value depends on the expression: A set of calls is represented by a sorted list without duplicates of call() . A set of constants is represented by a sorted list without duplicates of constant() . A set of strongly connected components is a sorted list without duplicates of Component . A set of calls between strongly connected components is a sorted list without duplicates of ComponentCall . A chain of calls is represented by a list of constant() . The list contains the From vertex of every call and the To vertex of the last call. The of operator returns false if no chain of calls between the given constants can be found. The value of the closure operator (the digraph representation) is represented by the atom 'closure()' . A set of line numbered functions is represented by a sorted list without duplicates of DefineAt . A set of line numbered function calls is represented by a sorted list without duplicates of CallAt . A set of line numbered functions and function calls is represented by a sorted list without duplicates of AllLines . For both CallAt and AllLines it holds that for no list element is LineNumbers an empty list; such elements have been removed. The constants of component and the integers of LineNumbers are sorted and without duplicates.","ref":"xref.html#q/2","title":"xref.q/2","type":"function"},{"doc":"","ref":"xref.html#q/3","title":"xref.q/3","type":"function"},{"doc":"Removes applications and their modules and module data from an Xref server .","ref":"xref.html#remove_application/2","title":"xref.remove_application/2","type":"function"},{"doc":"Removes analyzed modules and module data from an Xref server .","ref":"xref.html#remove_module/2","title":"xref.remove_module/2","type":"function"},{"doc":"Removes releases and their applications, modules and module data from an Xref server .","ref":"xref.html#remove_release/2","title":"xref.remove_release/2","type":"function"},{"doc":"Replaces the modules of an application with other modules read from an application directory. Release membership of the application is retained. Note that the name of the application is kept; the name of the given directory is not used.","ref":"xref.html#replace_application/3","title":"xref.replace_application/3","type":"function"},{"doc":"","ref":"xref.html#replace_application/4","title":"xref.replace_application/4","type":"function"},{"doc":"Replaces module data of an analyzed module with data read from a BEAM file. Application membership of the module is retained, and so is the value of the builtins option of the module. An error is returned if the name of the read module differs from the given module. The update function is an alternative for updating module data of recompiled modules.","ref":"xref.html#replace_module/3","title":"xref.replace_module/3","type":"function"},{"doc":"","ref":"xref.html#replace_module/4","title":"xref.replace_module/4","type":"function"},{"doc":"Sets the default value of one or more options. The options that can be set this way are: builtins , with initial default value false ; recurse , with initial default value false ; verbose , with initial default value false ; warnings , with initial default value true . The initial default values are set when creating an Xref server .","ref":"xref.html#set_default/2","title":"xref.set_default/2","type":"function"},{"doc":"","ref":"xref.html#set_default/3","title":"xref.set_default/3","type":"function"},{"doc":"Sets the library path . If the given path is a list of directories, the set of library modules is determined by choosing the first module encountered while traversing the directories in the given order, for those modules that occur in more than one directory. By default, the library path is an empty list. The library path code_path is used by the functions m/1 and d/1 , but can also be set explicitly. Note however that the code path will be traversed once for each used library module while setting up module data. On the other hand, if there are only a few modules that are used but not analyzed, using code_path may be faster than setting the library path to code:get_path() . If the library path is set to code_path , the set of library modules is not determined, and the info functions will return empty lists of library modules.","ref":"xref.html#set_library_path/2","title":"xref.set_library_path/2","type":"function"},{"doc":"","ref":"xref.html#set_library_path/3","title":"xref.set_library_path/3","type":"function"},{"doc":"Creates an Xref server . The process may optionally be given a name. The default mode is functions . Options that are not recognized by Xref are passed on to gen_server:start/4 .","ref":"xref.html#start/1","title":"xref.start/1","type":"function"},{"doc":"Creates an Xref server with a given name. The default mode is functions . Options that are not recognized by Xref are passed on to gen_server:start/4 .","ref":"xref.html#start/2","title":"xref.start/2","type":"function"},{"doc":"Stops an Xref server .","ref":"xref.html#stop/1","title":"xref.stop/1","type":"function"},{"doc":"Replaces the module data of all analyzed modules the BEAM files of which have been modified since last read by an add function or update . Application membership of the modules is retained, and so is the value of the builtins option. Returns a sorted list of the names of the replaced modules.","ref":"xref.html#update/1","title":"xref.update/1","type":"function"},{"doc":"","ref":"xref.html#update/2","title":"xref.update/2","type":"function"},{"doc":"Returns a sorted lists of the names of the variables of an Xref server . The default is to return the user variables only.","ref":"xref.html#variables/1","title":"xref.variables/1","type":"function"},{"doc":"","ref":"xref.html#variables/2","title":"xref.variables/2","type":"function"},{"doc":"","ref":"xref.html#t:application/0","title":"xref.application/0","type":"type"},{"doc":"","ref":"xref.html#t:call/0","title":"xref.call/0","type":"type"},{"doc":"","ref":"xref.html#t:constant/0","title":"xref.constant/0","type":"type"},{"doc":"","ref":"xref.html#t:directory/0","title":"xref.directory/0","type":"type"},{"doc":"","ref":"xref.html#t:file/0","title":"xref.file/0","type":"type"},{"doc":"","ref":"xref.html#t:file_error/0","title":"xref.file_error/0","type":"type"},{"doc":"","ref":"xref.html#t:funcall/0","title":"xref.funcall/0","type":"type"},{"doc":"","ref":"xref.html#t:function_name/0","title":"xref.function_name/0","type":"type"},{"doc":"","ref":"xref.html#t:library/0","title":"xref.library/0","type":"type"},{"doc":"","ref":"xref.html#t:library_path/0","title":"xref.library_path/0","type":"type"},{"doc":"","ref":"xref.html#t:mode/0","title":"xref.mode/0","type":"type"},{"doc":"","ref":"xref.html#t:path/0","title":"xref.path/0","type":"type"},{"doc":"","ref":"xref.html#t:release/0","title":"xref.release/0","type":"type"},{"doc":"","ref":"xref.html#t:string_position/0","title":"xref.string_position/0","type":"type"},{"doc":"","ref":"xref.html#t:variable/0","title":"xref.variable/0","type":"type"},{"doc":"","ref":"xref.html#t:xarity/0","title":"xref.xarity/0","type":"type"},{"doc":"","ref":"xref.html#t:xmfa/0","title":"xref.xmfa/0","type":"type"},{"doc":"","ref":"xref.html#t:xref/0","title":"xref.xref/0","type":"type"}]