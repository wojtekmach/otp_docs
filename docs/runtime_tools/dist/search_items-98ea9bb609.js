searchNodes=[{"doc":"This module implements a text based interface to the trace/3 and the trace_pattern/2 BIFs. It makes it possible to trace functions, processes, ports and messages. To quickly get started on tracing function calls you can use the following code in the Erlang shell: 1 &gt; dbg : tracer ( ) . %% Start the default trace message receiver { ok , &lt; 0.36 . 0 &gt; } 2 &gt; dbg : p ( all , c ) . %% Setup call (c) tracing on all processes { ok , [ { matched , nonode @ nohost , 26 } ] } 3 &gt; dbg : tp ( lists , seq , x ) . %% Setup an exception return trace (x) on lists:seq { ok , [ { matched , nonode @ nohost , 2 } , { saved , x } ] } 4 &gt; lists : seq ( 1 , 10 ) . ( &lt; 0.34 . 0 &gt; ) call lists : seq ( 1 , 10 ) ( &lt; 0.34 . 0 &gt; ) returned from lists : seq / 2 -&gt; [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 ] [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 ] For more examples of how to use dbg from the Erlang shell, see the simple example section. The utilities are also suitable to use in system testing on large systems, where other tools have too much impact on the system performance. Some primitive support for sequential tracing is also included, see the advanced topics section. Simple examples - tracing from the shell The simplest way of tracing from the Erlang shell is to use dbg:c/3 or dbg:c/4 , e.g. tracing the function dbg:get_tracer/0 : ( tiger @ durin ) 84 &gt; dbg : c ( dbg , get_tracer , [ ] ) . ( &lt; 0.154 . 0 &gt; ) &lt; 0.152 . 0 &gt; ! { &lt; 0.154 . 0 &gt; , { get_tracer , tiger @ durin } } ( &lt; 0.154 . 0 &gt; ) out { dbg , req , 1 } ( &lt; 0.154 . 0 &gt; ) &lt;&lt; { dbg , { ok , &lt; 0.153 . 0 &gt; } } ( &lt; 0.154 . 0 &gt; ) in { dbg , req , 1 } ( &lt; 0.154 . 0 &gt; ) &lt;&lt; timeout { ok , &lt; 0.153 . 0 &gt; } ( tiger @ durin ) 85 &gt; Another way of tracing from the shell is to explicitly start a tracer and then set the trace flags of your choice on the processes you want to trace, e.g. trace messages and process events: ( tiger @ durin ) 66 &gt; Pid = spawn ( fun ( ) -&gt; receive { From , Msg } -&gt; From ! Msg end end ) . &lt; 0.126 . 0 &gt; ( tiger @ durin ) 67 &gt; dbg : tracer ( ) . { ok , &lt; 0.128 . 0 &gt; } ( tiger @ durin ) 68 &gt; dbg : p ( Pid , [ m , procs ] ) . { ok , [ { matched , tiger @ durin , 1 } ] } ( tiger @ durin ) 69 &gt; Pid ! { self ( ) , hello } . ( &lt; 0.126 . 0 &gt; ) &lt;&lt; { &lt; 0.116 . 0 &gt; , hello } { &lt; 0.116 . 0 &gt; , hello } ( &lt; 0.126 . 0 &gt; ) &lt;&lt; timeout ( &lt; 0.126 . 0 &gt; ) &lt; 0.116 . 0 &gt; ! hello ( &lt; 0.126 . 0 &gt; ) exit normal ( tiger @ durin ) 70 &gt; flush ( ) . Shell got hello ok ( tiger @ durin ) 71 &gt; If you set the call trace flag, you also have to set a trace pattern for the functions you want to trace: ( tiger @ durin ) 77 &gt; dbg : tracer ( ) . { ok , &lt; 0.142 . 0 &gt; } ( tiger @ durin ) 78 &gt; dbg : p ( all , call ) . { ok , [ { matched , tiger @ durin , 3 } ] } ( tiger @ durin ) 79 &gt; dbg : tp ( dbg , get_tracer , 0 , [ ] ) . { ok , [ { matched , tiger @ durin , 1 } ] } ( tiger @ durin ) 80 &gt; dbg : get_tracer ( ) . ( &lt; 0.116 . 0 &gt; ) call dbg : get_tracer ( ) { ok , &lt; 0.143 . 0 &gt; } ( tiger @ durin ) 81 &gt; dbg : tp ( dbg , get_tracer , 0 , [ { &#39;_&#39; , [ ] , [ { return_trace } ] } ] ) . { ok , [ { matched , tiger @ durin , 1 } , { saved , 1 } ] } ( tiger @ durin ) 82 &gt; dbg : get_tracer ( ) . ( &lt; 0.116 . 0 &gt; ) call dbg : get_tracer ( ) ( &lt; 0.116 . 0 &gt; ) returned from dbg : get_tracer / 0 -&gt; { ok , &lt; 0.143 . 0 &gt; } { ok , &lt; 0.143 . 0 &gt; } ( tiger @ durin ) 83 &gt; Advanced topics - combining with seq_trace The dbg module is primarily targeted towards tracing through the erlang:trace/3 function. It is sometimes desired to trace messages in a more delicate way, which can be done with the help of the seq_trace module. seq_trace implements sequential tracing (known in the AXE10 world, and sometimes called &quot;forlopp tracing&quot;). dbg can interpret messages generated from seq_trace and the same tracer function for both types of tracing can be used. The seq_trace messages can even be sent to a trace port for further analysis. As a match specification can turn on sequential tracing, the combination of dbg and seq_trace can be quite powerful. This brief example shows a session where sequential tracing is used: 1 &gt; dbg : tracer ( ) . { ok , &lt; 0.30 . 0 &gt; } 2 &gt; { ok , Tracer } = dbg : get_tracer ( ) . { ok , &lt; 0.31 . 0 &gt; } 3 &gt; seq_trace : set_system_tracer ( Tracer ) . false 4 &gt; dbg : tp ( dbg , get_tracer , 0 , [ { [ ] , [ ] , [ { set_seq_token , send , true } ] } ] ) . { ok , [ { matched , nonode @ nohost , 1 } , { saved , 1 } ] } 5 &gt; dbg : p ( all , call ) . { ok , [ { matched , nonode @ nohost , 22 } ] } 6 &gt; dbg : get_tracer ( ) , seq_trace : set_token ( [ ] ) . ( &lt; 0.25 . 0 &gt; ) call dbg : get_tracer ( ) SeqTrace [ 0 ] : ( &lt; 0.25 . 0 &gt; ) &lt; 0.30 . 0 &gt; ! { &lt; 0.25 . 0 &gt; , get_tracer } [ Serial : { 2 , 4 } ] SeqTrace [ 0 ] : ( &lt; 0.30 . 0 &gt; ) &lt; 0.25 . 0 &gt; ! { dbg , { ok , &lt; 0.31 . 0 &gt; } } [ Serial : { 4 , 5 } ] { 1 , 0 , 5 , &lt; 0.30 . 0 &gt; , 4 } This session sets the system_tracer to the same process as the ordinary tracer process (i. e. &lt;0.31.0&gt;) and sets the trace pattern for the function dbg:get_tracer to one that has the action of setting a sequential token. When the function is called by a traced process (all processes are traced in this case), the process gets &quot;contaminated&quot; by the token and seq_trace messages are sent both for the server request and the response. The seq_trace:set_token([]) after the call clears the seq_trace token, why no messages are sent when the answer propagates via the shell to the console port. The output would otherwise have been more noisy. Note of caution When tracing function calls on a group leader process (an IO process), there is risk of causing a deadlock. This will happen if a group leader process generates a trace message and the tracer process, by calling the trace handler function, sends an IO request to the same group leader. The problem can only occur if the trace handler prints to tty using an io function such as format/2 . Note that when dbg:p(all,call) is called, IO processes are also traced. Here's an example: %% Using a default line editing shell 1 &gt; dbg : tracer ( process , { fun ( Msg , _ ) -&gt; io : format ( &quot; ~p ~n &quot; , [ Msg ] ) , 0 end , 0 } ) . { ok , &lt; 0.37 . 0 &gt; } 2 &gt; dbg : p ( all , [ call ] ) . { ok , [ { matched , nonode @ nohost , 25 } ] } 3 &gt; dbg : tp ( mymod , [ { &#39;_&#39; , [ ] , [ ] } ] ) . { ok , [ { matched , nonode @ nohost , 0 } , { saved , 1 } ] } 4 &gt; mymod : % TAB pressed here %% -- Deadlock -- Here's another example: %% Using a shell without line editing (oldshell) 1 &gt; dbg : tracer ( process ) . { ok , &lt; 0.31 . 0 &gt; } 2 &gt; dbg : p ( all , [ call ] ) . { ok , [ { matched , nonode @ nohost , 25 } ] } 3 &gt; dbg : tp ( lists , [ { &#39;_&#39; , [ ] , [ ] } ] ) . { ok , [ { matched , nonode @ nohost , 0 } , { saved , 1 } ] } % -- Deadlock -- The reason we get a deadlock in the first example is because when TAB is pressed to expand the function name, the group leader (which handles character input) calls mymod:module_info() . This generates a trace message which, in turn, causes the tracer process to send an IO request to the group leader (by calling io:format/2 ). We end up in a deadlock. In the second example we use the default trace handler function. This handler prints to tty by sending IO requests to the user process. When Erlang is started in oldshell mode, the shell process will have user as its group leader and so will the tracer process in this example. Since user calls functions in lists we end up in a deadlock as soon as the first IO request is sent. Here are a few suggestions for how to avoid deadlock: Don't trace the group leader of the tracer process. If tracing has been switched on for all processes, call dbg:p(TracerGLPid,clear) to stop tracing the group leader ( TracerGLPid ). process_info(TracerPid,group_leader) tells you which process this is ( TracerPid is returned from dbg:get_tracer/0 ). Don't trace the user process if using the default trace handler function. In your own trace handler function, call erlang:display/1 instead of an io function or, if user is not used as group leader, print to user instead of the default group leader. Example: io:format(user,Str,Args) .","ref":"dbg.html","title":"dbg","type":"module"},{"doc":"Equivalent to c(Mod, Fun, Args, all) .","ref":"dbg.html#c/3","title":"dbg.c/3","type":"function"},{"doc":"c stands for c all. Evaluates the expression apply(Mod, Fun, Args) with the trace flags in Flags set. This is a convenient way to trace processes from the Erlang shell.","ref":"dbg.html#c/4","title":"dbg.c/4","type":"function"},{"doc":"Nodename = atom() cn stands for c lear n ode. Clears a node from the list of traced nodes. Subsequent calls to tp/2 and p/2 will not consider that node, but tracing already activated on the node will continue to be in effect. Returns ok , cannot fail.","ref":"dbg.html#cn/1","title":"dbg.cn/1","type":"function"},{"doc":"Same as ctp({'_', '_', '_'})","ref":"dbg.html#ctp/0","title":"dbg.ctp/0","type":"function"},{"doc":"Same as ctp({Module, '_', '_'})","ref":"dbg.html#ctp/1","title":"dbg.ctp/1","type":"function"},{"doc":"Module = atom() | '_' Function = atom() | '_' Arity = integer() | '_' MatchDesc = [MatchNum] MatchNum = {matched, node(), integer()} | {matched, node(), 0, RPCError} ctp stands for c lear t race p attern. This function disables call tracing on the specified functions. The semantics of the parameter is the same as for the corresponding function specification in tp/2 or tpl/2 . Both local and global call trace is disabled. The return value reflects how many functions that matched, and is constructed as described in tp/2 . No tuple {saved, N} is however ever returned (for obvious reasons).","ref":"dbg.html#ctp/1","title":"dbg.ctp/1","type":"function"},{"doc":"Same as ctp({Module, Function, '_'})","ref":"dbg.html#ctp/2","title":"dbg.ctp/2","type":"function"},{"doc":"Same as ctp({Module, Function, Arity})","ref":"dbg.html#ctp/3","title":"dbg.ctp/3","type":"function"},{"doc":"Event = send | 'receive' MatchDesc = [MatchNum] MatchNum = {matched, node(), 1} | {matched, node(), 0, RPCError} ctpe stands for c lear t race p attern e vent. This function clears match specifications for the specified trace event ( send or 'receive' ). It will revert back to the default behavior of tracing all triggered events. The return value follow the same style as for ctp/1 .","ref":"dbg.html#ctpe/1","title":"dbg.ctpe/1","type":"function"},{"doc":"Same as ctpg({'_', '_', '_'})","ref":"dbg.html#ctpg/0","title":"dbg.ctpg/0","type":"function"},{"doc":"Same as ctpg({Module, '_', '_'})","ref":"dbg.html#ctpg/1","title":"dbg.ctpg/1","type":"function"},{"doc":"ctpg stands for c lear t race p attern g lobal. This function works as ctp/1 , but only disables tracing set up with tp/2 (not with tpl/2 ).","ref":"dbg.html#ctpg/1","title":"dbg.ctpg/1","type":"function"},{"doc":"Same as ctpg({Module, Function, '_'})","ref":"dbg.html#ctpg/2","title":"dbg.ctpg/2","type":"function"},{"doc":"Same as ctpg({Module, Function, Arity})","ref":"dbg.html#ctpg/3","title":"dbg.ctpg/3","type":"function"},{"doc":"Same as ctpl({'_', '_', '_'})","ref":"dbg.html#ctpl/0","title":"dbg.ctpl/0","type":"function"},{"doc":"Same as ctpl({Module, '_', '_'})","ref":"dbg.html#ctpl/1","title":"dbg.ctpl/1","type":"function"},{"doc":"ctpl stands for c lear t race p attern l ocal. This function works as ctp/1 , but only disables tracing set up with tpl/2 (not with tp/2 ).","ref":"dbg.html#ctpl/1","title":"dbg.ctpl/1","type":"function"},{"doc":"Same as ctpl({Module, Function, '_'})","ref":"dbg.html#ctpl/2","title":"dbg.ctpl/2","type":"function"},{"doc":"Same as ctpl({Module, Function, Arity})","ref":"dbg.html#ctpl/3","title":"dbg.ctpl/3","type":"function"},{"doc":"dtp stands for d elete t race p atterns. Use this function to &quot;forget&quot; all match specifications saved during calls to tp/2 . This is useful when one wants to restore other match specifications from a file with rtp/1 . Use dtp/1 to delete specific saved match specifications.","ref":"dbg.html#dtp/0","title":"dbg.dtp/0","type":"function"},{"doc":"N = integer() dtp stands for d elete t race p attern. Use this function to &quot;forget&quot; a specific match specification saved during calls to tp/2 .","ref":"dbg.html#dtp/1","title":"dbg.dtp/1","type":"function"},{"doc":"Equivalent to flush_trace_port(node()) .","ref":"dbg.html#flush_trace_port/0","title":"dbg.flush_trace_port/0","type":"function"},{"doc":"Equivalent to trace_port_control(Nodename,flush) .","ref":"dbg.html#flush_trace_port/1","title":"dbg.flush_trace_port/1","type":"function"},{"doc":"LiteralFun = fun() literal MatchSpec = term() Pseudo function that by means of a parse_transform translates the literal fun() typed as parameter in the function call to a match specification as described in the match_spec manual of ERTS users guide. (With literal I mean that the fun() needs to textually be written as the parameter of the function, it cannot be held in a variable which in turn is passed to the function). The parse transform is implemented in the module ms_transform and the source must include the file ms_transform.hrl in STDLIB for this pseudo function to work. Failing to include the hrl file in the source will result in a runtime error, not a compile time ditto. The include file is easiest included by adding the line -include_lib(&quot;stdlib/include/ms_transform.hrl&quot;). to the source file. The fun() is very restricted, it can take only a single parameter (the parameter list to match), a sole variable or a list. It needs to use the is_ XXX guard tests and one cannot use language constructs that have no representation in a match_spec (like if , case , receive etc). The return value from the fun will be the return value of the resulting match_spec. Example: 1 &gt; dbg : fun2ms ( fun ( [ M , N ] ) when N &gt; 3 -&gt; return_trace ( ) end ) . [ { [ &#39;$1&#39; , &#39;$2&#39; ] , [ { &#39;&gt;&#39; , &#39;$2&#39; , 3 } ] , [ { return_trace } ] } ] Variables from the environment can be imported, so that this works: 2 &gt; X = 3 . 3 3 &gt; dbg : fun2ms ( fun ( [ M , N ] ) when N &gt; X -&gt; return_trace ( ) end ) . [ { [ &#39;$1&#39; , &#39;$2&#39; ] , [ { &#39;&gt;&#39; , &#39;$2&#39; , { const , 3 } } ] , [ { return_trace } ] } ] The imported variables will be replaced by match_spec const expressions, which is consistent with the static scoping for Erlang fun() s. Local or global function calls cannot be in the guard or body of the fun however. Calls to builtin match_spec functions of course is allowed: 4 &gt; dbg : fun2ms ( fun ( [ M , N ] ) when N &gt; X , is_atomm ( M ) -&gt; return_trace ( ) end ) . Error : fun containing local erlang function calls ( &#39;is_atomm&#39; called in guard ) \\ cannot be translated into match_spec { error , transform_error } 5 &gt; dbg : fun2ms ( fun ( [ M , N ] ) when N &gt; X , is_atom ( M ) -&gt; return_trace ( ) end ) . [ { [ &#39;$1&#39; , &#39;$2&#39; ] , [ { &#39;&gt;&#39; , &#39;$2&#39; , { const , 3 } } , { is_atom , &#39;$1&#39; } ] , [ { return_trace } ] } ] As you can see by the example, the function can be called from the shell too. The fun() needs to be literally in the call when used from the shell as well. Other means than the parse_transform are used in the shell case, but more or less the same restrictions apply (the exception being records, as they are not handled by the shell). If the parse_transform is not applied to a module which calls this pseudo function, the call will fail in runtime (with a badarg ). The module dbg actually exports a function with this name, but it should never really be called except for when using the function in the shell. If the parse_transform is properly applied by including the ms_transform.hrl header file, compiled code will never call the function, but the function call is replaced by a literal match_spec. More information is provided by the ms_transform manual page in STDLIB.","ref":"dbg.html#fun2ms/1","title":"dbg.fun2ms/1","type":"function"},{"doc":"Equivalent to get_tracer(node()) .","ref":"dbg.html#get_tracer/0","title":"dbg.get_tracer/0","type":"function"},{"doc":"Nodename = atom() Tracer = port() | pid() | {module(), term()} Returns the process, port or tracer module to which all trace messages are sent.","ref":"dbg.html#get_tracer/1","title":"dbg.get_tracer/1","type":"function"},{"doc":"h stands for h elp. Gives a list of items for brief online help.","ref":"dbg.html#h/0","title":"dbg.h/0","type":"function"},{"doc":"Item = atom() h stands for h elp. Gives a brief help text for functions in the dbg module. The available items can be listed with dbg:h/0 .","ref":"dbg.html#h/1","title":"dbg.h/1","type":"function"},{"doc":"i stands for i nformation. Displays information about all traced processes and ports.","ref":"dbg.html#i/0","title":"dbg.i/0","type":"function"},{"doc":"ln stands for l ist n odes. Shows the list of traced nodes on the console.","ref":"dbg.html#ln/0","title":"dbg.ln/0","type":"function"},{"doc":"ltp stands for l ist t race p atterns. Use this function to recall all match specifications previously used in the session (i. e. previously saved during calls to tp/2 , and built-in match specifications. This is very useful, as a complicated match_spec can be quite awkward to write. Note that the match specifications are lost if stop/0 is called. Match specifications used can be saved in a file (if a read-write file system is present) for use in later debugging sessions, see wtp/1 and rtp/1 There are three built-in trace patterns: exception_trace , caller_trace and caller_exception_trace (or x , c and cx respectively). Exception trace sets a trace which will show function names, parameters, return values and exceptions thrown from functions. Caller traces display function names, parameters and information about which function called it. An example using a built-in alias: ( x @ y ) 4 &gt; dbg : tp ( lists , sort , cx ) . { ok , [ { matched , nonode @ nohost , 2 } , { saved , cx } ] } ( x @ y ) 4 &gt; lists : sort ( [ 2 , 1 ] ) . ( &lt; 0.32 . 0 &gt; ) call lists : sort ( [ 2 , 1 ] ) ( { erl_eval , do_apply , 5 } ) ( &lt; 0.32 . 0 &gt; ) returned from lists : sort / 1 -&gt; [ 1 , 2 ] [ 1 , 2 ]","ref":"dbg.html#ltp/0","title":"dbg.ltp/0","type":"function"},{"doc":"Nodename = atom() Reason = term() n stands for n ode. The dbg server keeps a list of nodes where tracing should be performed. Whenever a tp/2 call or a p/2 call is made, it is executed for all nodes in this list including the local node (except for p/2 with a specific pid() or port() as first argument, in which case the command is executed only on the node where the designated process or port resides). This function adds a remote node ( Nodename ) to the list of nodes where tracing is performed. It starts a tracer process on the remote node, which will send all trace messages to the tracer process on the local node (via the Erlang distribution). If no tracer process is running on the local node, the error reason no_local_tracer is returned. The tracer process on the local node must be started with the tracer/0/2 function. If Nodename is the local node, the error reason cant_add_local_node is returned. If a trace port (see trace_port/2 ) is running on the local node, remote nodes cannot be traced with a tracer process. The error reason cant_trace_remote_pid_to_local_port is returned. A trace port can however be started on the remote node with the tracer/3 function. The function will also return an error if the node Nodename is not reachable.","ref":"dbg.html#n/1","title":"dbg.n/1","type":"function"},{"doc":"Equivalent to p(Item, [m]) .","ref":"dbg.html#p/1","title":"dbg.p/1","type":"function"},{"doc":"MatchDesc = [MatchNum] MatchNum = {matched, node(), integer()} | {matched, node(), 0, RPCError} RPCError = term() p stands for p rocess. Traces Item in accordance to the value specified by Flags . The variation of Item is listed below: pid() or port() The corresponding process or port is traced. The process or port may be a remote process or port (on another Erlang node). The node must be in the list of traced nodes (see n/1 and tracer/3 ). all All processes and ports in the system as well as all processes and ports created hereafter are to be traced. processes All processes in the system as well as all processes created hereafter are to be traced. ports All ports in the system as well as all ports created hereafter are to be traced. new All processes and ports created after the call is are to be traced. new_processes All processes created after the call is are to be traced. new_ports All ports created after the call is are to be traced. existing All existing processes and ports are traced. existing_processes All existing processes are traced. existing_ports All existing ports are traced. atom() The process or port with the corresponding registered name is traced. The process or port may be a remote process (on another Erlang node). The node must be added with the n/1 or tracer/3 function. integer() The process &lt;0.Item.0&gt; is traced. {X, Y, Z} The process &lt;X.Y.Z&gt; is traced. string() If the Item is a string &quot;&lt;X.Y.Z&gt;&quot; as returned from pid_to_list/1 , the process &lt;X.Y.Z&gt; is traced. When enabling an Item that represents a group of processes, the Item is enabled on all nodes added with the n/1 or tracer/3 function. Flags can be a single atom, or a list of flags. The available flags are: s (send) Traces the messages the process or port sends. r (receive) Traces the messages the process or port receives. m (messages) Traces the messages the process or port receives and sends. c (call) Traces global function calls for the process according to the trace patterns set in the system (see tp/2). p (procs) Traces process related events to the process. ports Traces port related events to the port. sos (set on spawn) Lets all processes created by the traced process inherit the trace flags of the traced process. sol (set on link) Lets another process, P2 , inherit the trace flags of the traced process whenever the traced process links to P2 . sofs (set on first spawn) This is the same as sos , but only for the first process spawned by the traced process. sofl (set on first link) This is the same as sol , but only for the first call to link/1 by the traced process. all Sets all flags except silent . clear Clears all flags. The list can also include any of the flags allowed in erlang:trace/3 The function returns either an error tuple or a tuple {ok, List} . The List consists of specifications of how many processes and ports that matched (in the case of a pure pid() exactly 1). The specification of matched processes is {matched, Node, N} . If the remote processor call, rpc , to a remote node fails, the rpc error message is delivered as a fourth argument and the number of matched processes are 0. Note that the result {ok, List} may contain a list where rpc calls to one, several or even all nodes failed.","ref":"dbg.html#p/2","title":"dbg.p/2","type":"function"},{"doc":"Name = string() Error = term() rtp stands for r ead t race p atterns. This function reads match specifications from a file (possibly) generated by the wtp/1 function. It checks the syntax of all match specifications and verifies that they are correct. The error handling principle is &quot;all or nothing&quot;, i. e. if some of the match specifications are wrong, none of the specifications are added to the list of saved match specifications for the running system. The match specifications in the file are merged with the current match specifications, so that no duplicates are generated. Use ltp/0 to see what numbers were assigned to the specifications from the file. The function will return an error, either due to I/O problems (like a non existing or non readable file) or due to file format problems. The errors from a bad format file are in a more or less textual format, which will give a hint to what's causing the problem.","ref":"dbg.html#rtp/1","title":"dbg.rtp/1","type":"function"},{"doc":"Stops the dbg server and clears all trace flags for all processes and all local trace patterns for all functions. Also shuts down all trace clients and closes all trace ports. Note that no global trace patterns are affected by this function.","ref":"dbg.html#stop/0","title":"dbg.stop/0","type":"function"},{"doc":"Same as stop/0, but also clears all trace patterns on global functions calls.","ref":"dbg.html#stop_clear/0","title":"dbg.stop_clear/0","type":"function"},{"doc":"Pid = pid() This function shuts down a previously started trace client. The Pid argument is the process id returned from the trace_client/2 or trace_client/3 call.","ref":"dbg.html#stop_trace_client/1","title":"dbg.stop_trace_client/1","type":"function"},{"doc":"Same as tp({Module, '_', '_'}, MatchSpec)","ref":"dbg.html#tp/2","title":"dbg.tp/2","type":"function"},{"doc":"Module = atom() | '_' Function = atom() | '_' Arity = integer() |'_' MatchSpec = integer() | Built-inAlias | [] | match_spec() Built-inAlias = x | c | cx MatchDesc = [MatchInfo] MatchInfo = {saved, integer()} | MatchNum MatchNum = {matched, node(), integer()} | {matched, node(), 0, RPCError} tp stands for t race p attern. This function enables call trace for one or more functions. All exported functions matching the {Module, Function, Arity} argument will be concerned, but the match_spec() may further narrow down the set of function calls generating trace messages. For a description of the match_spec() syntax, please turn to the User's guide part of the online documentation for the runtime system ( erts ). The chapter Match Specifications in Erlang explains the general match specification &quot;language&quot;. The most common generic match specifications used can be found as Built-inAlias ', see ltp/0 below for details. The Module, Function and/or Arity parts of the tuple may be specified as the atom '_' which is a &quot;wild-card&quot; matching all modules/functions/arities. Note, if the Module is specified as '_' , the Function and Arity parts have to be specified as '_' too. The same holds for the Functions relation to the Arity. All nodes added with n/1 or tracer/3 will be affected by this call, and if Module is not '_' the module will be loaded on all nodes. The function returns either an error tuple or a tuple {ok, List} . The List consists of specifications of how many functions that matched, in the same way as the processes and ports are presented in the return value of p/2 . There may be a tuple {saved, N} in the return value, if the MatchSpec is other than []. The integer N may then be used in subsequent calls to this function and will stand as an &quot;alias&quot; for the given expression. There are also a couple of built-in aliases for common expressions, see ltp/0 below for details. If an error is returned, it can be due to errors in compilation of the match specification. Such errors are presented as a list of tuples {error, string()} where the string is a textual explanation of the compilation error. An example: ( x @ y ) 4 &gt; dbg : tp ( { dbg , ltp , 0 } , [ { [ ] , [ ] , [ { message , two , arguments } , { noexist } ] } ] ) . { error , [ { error , &quot;Special form &#39;message&#39; called with wrong number of arguments in {message,two,arguments}.&quot; } , { error , &quot;Function noexist/1 does_not_exist.&quot; } ] }","ref":"dbg.html#tp/2","title":"dbg.tp/2","type":"function"},{"doc":"Same as tp({Module, Function, '_'}, MatchSpec)","ref":"dbg.html#tp/3","title":"dbg.tp/3","type":"function"},{"doc":"Same as tp({Module, Function, Arity}, MatchSpec)","ref":"dbg.html#tp/4","title":"dbg.tp/4","type":"function"},{"doc":"Event = send | 'receive' MatchSpec = integer() | Built-inAlias | [] | match_spec() Built-inAlias = x | c | cx MatchDesc = [MatchInfo] MatchInfo = {saved, integer()} | MatchNum MatchNum = {matched, node(), 1} | {matched, node(), 0, RPCError} tpe stands for t race p attern e vent. This function associates a match specification with trace event send or 'receive' . By default all executed send and 'receive' events are traced if enabled for a process. A match specification can be used to filter traced events based on sender, receiver and/or message content. For a description of the match_spec() syntax, please turn to the User's guide part of the online documentation for the runtime system ( erts ). The chapter Match Specifications in Erlang explains the general match specification &quot;language&quot;. For send , the matching is done on the list [Receiver, Msg] . Receiver is the process or port identity of the receiver and Msg is the message term. The pid of the sending process can be accessed with the guard function self/0 . For 'receive' , the matching is done on the list [Node, Sender, Msg] . Node is the node name of the sender. Sender is the process or port identity of the sender, or the atom undefined if the sender is not known (which may be the case for remote senders). Msg is the message term. The pid of the receiving process can be accessed with the guard function self/0 . All nodes added with n/1 or tracer/3 will be affected by this call. The return value is the same as for tp/2 . The number of matched events are never larger than 1 as tpe/2 does not accept any form of wildcards for argument Event .","ref":"dbg.html#tpe/2","title":"dbg.tpe/2","type":"function"},{"doc":"Same as tpl({Module, '_', '_'}, MatchSpec)","ref":"dbg.html#tpl/2","title":"dbg.tpl/2","type":"function"},{"doc":"tpl stands for t race p attern l ocal. This function works as tp/2 , but enables tracing for local calls (and local functions) as well as for global calls (and functions).","ref":"dbg.html#tpl/2","title":"dbg.tpl/2","type":"function"},{"doc":"Same as tpl({Module, Function, '_'}, MatchSpec)","ref":"dbg.html#tpl/3","title":"dbg.tpl/3","type":"function"},{"doc":"Same as tpl({Module, Function, Arity}, MatchSpec)","ref":"dbg.html#tpl/4","title":"dbg.tpl/4","type":"function"},{"doc":"Type = ip | file | follow_file Parameters = Filename | WrapFilesSpec | IPClientPortSpec Filename = string() | [string()] | atom() WrapFilesSpec = see trace_port/2 Suffix = string() IpClientPortSpec = PortNumber | {Hostname, PortNumber} PortNumber = integer() Hostname = string() This function starts a trace client that reads the output created by a trace port driver and handles it in mostly the same way as a tracer process created by the tracer/0 function. If Type is file , the client reads all trace messages stored in the file named Filename or specified by WrapFilesSpec (must be the same as used when creating the trace, see trace_port/2) and let's the default handler function format the messages on the console. This is one way to interpret the data stored in a file by the file trace port driver. If Type is follow_file , the client behaves as in the file case, but keeps trying to read (and process) more data from the file until stopped by stop_trace_client/1 . WrapFilesSpec is not allowed as second argument for this Type . If Type is ip , the client connects to the TCP/IP port PortNumber on the host Hostname , from where it reads trace messages until the TCP/IP connection is closed. If no Hostname is specified, the local host is assumed. As an example, one can let trace messages be sent over the network to another Erlang node (preferably not distributed), where the formatting occurs: On the node stack there's an Erlang node ant@stack , in the shell, type the following: ant @ stack &gt; dbg : tracer ( port , dbg : trace_port ( ip , 4711 ) ) . &lt; 0.17 . 0 &gt; ant @ stack &gt; dbg : p ( self ( ) , send ) . { ok , 1 } All trace messages are now sent to the trace port driver, which in turn listens for connections on the TCP/IP port 4711. If we want to see the messages on another node, preferably on another host, we do like this: -&gt; dbg : trace_client ( ip , { &quot;stack&quot; , 4711 } ) . &lt; 0.42 . 0 &gt; If we now send a message from the shell on the node ant@stack , where all sends from the shell are traced: ant @ stack &gt; self ( ) ! hello . hello The following will appear at the console on the node that started the trace client: ( &lt; 0.23 . 0 &gt; ) &lt; 0.23 . 0 &gt; ! hello ( &lt; 0.23 . 0 &gt; ) &lt; 0.22 . 0 &gt; ! { shell_rep , &lt; 0.23 . 0 &gt; , { value , hello , [ ] , [ ] } } The last line is generated due to internal message passing in the Erlang shell. The process id's will vary.","ref":"dbg.html#trace_client/2","title":"dbg.trace_client/2","type":"function"},{"doc":"Type = ip | file | follow_file Parameters = Filename | WrapFilesSpec | IPClientPortSpec Filename = string() | [string()] | atom() WrapFilesSpec = see trace_port/2 Suffix = string() IpClientPortSpec = PortNumber | {Hostname, PortNumber} PortNumber = integer() Hostname = string() HandlerSpec = {HandlerFun, InitialData} HandlerFun = fun() (two arguments) InitialData = term() This function works exactly as trace_client/2 , but allows you to write your own handler function. The handler function works mostly as the one described in tracer/2 , but will also have to be prepared to handle trace messages of the form {drop, N} , where N is the number of dropped messages. This pseudo trace message will only occur if the ip trace driver is used. For trace type file , the pseudo trace message end_of_trace will appear at the end of the trace. The return value from the handler function is in this case ignored.","ref":"dbg.html#trace_client/3","title":"dbg.trace_client/3","type":"function"},{"doc":"Type = ip | file Parameters = Filename | WrapFilesSpec | IPPortSpec Filename = string() | [string()] | atom() WrapFilesSpec = {Filename, wrap, Suffix} | {Filename, wrap, Suffix, WrapSize} | {Filename, wrap, Suffix, WrapSize, WrapCnt} Suffix = string() WrapSize = integer() &gt;= 0 | {time, WrapTime} WrapTime = integer() &gt;= 1 WrapCnt = integer() &gt;= 1 IpPortSpec = PortNumber | {PortNumber, QueSize} PortNumber = integer() QueSize = integer() This function creates a trace port generating fun . The fun takes no arguments and returns a newly opened trace port. The return value from this function is suitable as a second parameter to tracer/2, i.e. dbg:tracer(port, dbg:trace_port(ip, 4711)) . A trace port is an Erlang port to a dynamically linked in driver that handles trace messages directly, without the overhead of sending them as messages in the Erlang virtual machine. Two trace drivers are currently implemented, the file and the ip trace drivers. The file driver sends all trace messages into one or several binary files, from where they later can be fetched and processed with the trace_client/2 function. The ip driver opens a TCP/IP port where it listens for connections. When a client (preferably started by calling trace_client/2 on another Erlang node) connects, all trace messages are sent over the IP network for further processing by the remote client. Using a trace port significantly lowers the overhead imposed by using tracing. The file trace driver expects a filename or a wrap files specification as parameter. A file is written with a high degree of buffering, why all trace messages are not guaranteed to be saved in the file in case of a system crash. That is the price to pay for low tracing overhead. A wrap files specification is used to limit the disk space consumed by the trace. The trace is written to a limited number of files each with a limited size. The actual filenames are Filename ++ SeqCnt ++ Suffix , where SeqCnt counts as a decimal string from 0 to WrapCnt and then around again from 0 . When a trace term written to the current file makes it longer than WrapSize , that file is closed, if the number of files in this wrap trace is as many as WrapCnt the oldest file is deleted then a new file is opened to become the current. Thus, when a wrap trace has been stopped, there are at most WrapCnt trace files saved with a size of at least WrapSize (but not much bigger), except for the last file that might even be empty. The default values are WrapSize = 128*1024 and WrapCnt = 8 . The SeqCnt values in the filenames are all in the range 0 through WrapCnt with a gap in the circular sequence. The gap is needed to find the end of the trace. If the WrapSize is specified as {time, WrapTime} , the current file is closed when it has been open more than WrapTime milliseconds, regardless of it being empty or not. The ip trace driver has a queue of QueSize messages waiting to be delivered. If the driver cannot deliver messages as fast as they are produced by the runtime system, a special message is sent, which indicates how many messages that are dropped. That message will arrive at the handler function specified in trace_client/3 as the tuple {drop, N} where N is the number of consecutive messages dropped. In case of heavy tracing, drop's are likely to occur, and they surely occur if no client is reading the trace messages. The default value of QueSize is 200.","ref":"dbg.html#trace_port/2","title":"dbg.trace_port/2","type":"function"},{"doc":"Equivalent to trace_port_control(node(),Operation) .","ref":"dbg.html#trace_port_control/1","title":"dbg.trace_port_control/1","type":"function"},{"doc":"Nodename = atom() This function is used to do a control operation on the active trace port driver on the given node ( Nodename ). Which operations are allowed as well as their return values depend on which trace driver is used. Returns either ok or {ok, Result} if the operation was successful, or {error, Reason} if the current tracer is a process or if it is a port not supporting the operation. The allowed values for Operation are: flush This function is used to flush the internal buffers held by a trace port driver. Currently only the file trace driver supports this operation. Returns ok . get_listen_port Returns {ok, IpPort} where IpPort is the IP port number used by the driver listen socket. Only the ip trace driver supports this operation.","ref":"dbg.html#trace_port_control/2","title":"dbg.trace_port_control/2","type":"function"},{"doc":"This function starts a server on the local node that will be the recipient of all trace messages. All subsequent calls to p/2 will result in messages sent to the newly started trace server. A trace server started in this way will simply display the trace messages in a formatted way in the Erlang shell (i. e. use io:format). See tracer/2 for a description of how the trace message handler can be customized. To start a similar tracer on a remote node, use n/1 .","ref":"dbg.html#tracer/0","title":"dbg.tracer/0","type":"function"},{"doc":"Type = port | process | module Data = PortGenerator | HandlerSpec | ModuleSpec PortGenerator = fun() (no arguments) Error = term() HandlerSpec = {HandlerFun, InitialData} HandlerFun = fun() (two arguments) ModuleSpec = fun() (no arguments) | {TracerModule, TracerState} TracerModule = atom() InitialData = TracerState = term() This function starts a tracer server with additional parameters on the local node. The first parameter, the Type , indicates if trace messages should be handled by a receiving process ( process ), by a tracer port ( port ) or by a tracer module ( module ). For a description about tracer ports see trace_port/2 and for a tracer modules see erl_tracer . If Type is process , a message handler function can be specified ( HandlerSpec ). The handler function, which should be a fun taking two arguments, will be called for each trace message, with the first argument containing the message as it is and the second argument containing the return value from the last invocation of the fun. The initial value of the second parameter is specified in the InitialData part of the HandlerSpec . The HandlerFun may choose any appropriate action to take when invoked, and can save a state for the next invocation by returning it. If Type is port , then the second parameter should be a fun which takes no arguments and returns a newly opened trace port when called. Such a fun is preferably generated by calling trace_port/2 . if Type is module , then the second parameter should be either a tuple describing the erl_tracer module to be used for tracing and the state to be used for that tracer module or a fun returning the same tuple. If an error is returned, it can either be due to a tracer server already running ( {error,already_started} ) or due to the HandlerFun throwing an exception. To start a similar tracer on a remote node, use tracer/3 .","ref":"dbg.html#tracer/2","title":"dbg.tracer/2","type":"function"},{"doc":"Nodename = atom() This function is equivalent to tracer/2 , but acts on the given node. A tracer is started on the node ( Nodename ) and the node is added to the list of traced nodes. This function is not equivalent to n/1 . While n/1 starts a process tracer which redirects all trace information to a process tracer on the local node (i.e. the trace control node), tracer/3 starts a tracer of any type which is independent of the tracer on the trace control node. For details, see tracer/2 .","ref":"dbg.html#tracer/3","title":"dbg.tracer/3","type":"function"},{"doc":"Name = string() IOError = term() wtp stands for w rite t race p atterns. This function will save all match specifications saved during the session (during calls to tp/2 ) and built-in match specifications in a text file with the name designated by Name . The format of the file is textual, why it can be edited with an ordinary text editor, and then restored with rtp/1 . Each match spec in the file ends with a full stop ( . ) and new (syntactically correct) match specifications can be added to the file manually. The function returns ok or an error tuple where the second element contains the I/O error that made the writing impossible.","ref":"dbg.html#wtp/1","title":"dbg.wtp/1","type":"function"},{"doc":"This module implements interfaces to dynamic tracing, should such be compiled into the virtual machine. For a standard and/or commercial build, no dynamic tracing is available, in which case none of the functions in this module is usable or give any effect. Should dynamic tracing be enabled in the current build, either by configuring with ./configure --with-dynamic-trace=dtrace or with ./configure --with-dynamic-trace=systemtap , the module can be used for two things: Trigger the user-probe user_trace_i4s4 in the NIF library dyntrace.so by calling dyntrace:p/{1,2,3,4,5,6,7,8} . Set a user specified tag that will be present in the trace messages of both the efile_drv and the user-probe mentioned above. Both building with dynamic trace probes and using them is experimental and unsupported by Erlang/OTP. It is included as an option for the developer to trace and debug performance issues in their systems. The original implementation is mostly done by Scott Lystiger Fritchie as an Open Source Contribution and it should be viewed as such even though the source for dynamic tracing as well as this module is included in the main distribution. However, the ability to use dynamic tracing of the virtual machine is a very valuable contribution which OTP has every intention to maintain as a tool for the developer. How to write d programs or systemtap scripts can be learned from books and from a lot of pages on the Internet. This manual page does not include any documentation about using the dynamic trace tools of respective platform. The examples directory of the runtime_tools application however contains comprehensive examples of both d and systemtap programs that will help you get started. Another source of information is the dtrace and systemtap chapters in the Runtime Tools Users' Guide.","ref":"dyntrace.html","title":"dyntrace","type":"module"},{"doc":"This function uses the NIF library to determine if dynamic tracing is available. Usually calling erlang:system_info/1 is a better indicator of the availability of dynamic tracing. The function will throw an exception if the dyntrace NIF library could not be loaded by the on_load function of this module.","ref":"dyntrace.html#available/0","title":"dyntrace.available/0","type":"function"},{"doc":"This function returns the user tag set in the current process. If no tag is set or dynamic tracing is not available, it returns undefined","ref":"dyntrace.html#get_tag/0","title":"dyntrace.get_tag/0","type":"function"},{"doc":"This function returns the user tag set in the current process or, if no user tag is present, the last user tag sent to the process together with a message (in the same way as sequential trace tokens are spread to other processes together with messages. For an explanation of how user tags can be spread together with messages, see spread_tag/1 . If no tag is found or dynamic tracing is not available, it returns undefined","ref":"dyntrace.html#get_tag/0","title":"dyntrace.get_tag/0","type":"function"},{"doc":"Calling this function will trigger the &quot;user&quot; trace probe user_trace_i4s4 in the dyntrace NIF module, sending a trace message only containing the user tag and zeroes/empty strings in all other fields.","ref":"dyntrace.html#p/0","title":"dyntrace.p/0","type":"function"},{"doc":"Calling this function will trigger the &quot;user&quot; trace probe user_trace_i4s4 in the dyntrace NIF module, sending a trace message containing the user tag and the integer or string parameter in the first integer/string field.","ref":"dyntrace.html#p/1","title":"dyntrace.p/1","type":"function"},{"doc":"Calling this function will trigger the &quot;user&quot; trace probe user_trace_i4s4 in the dyntrace NIF module, sending a trace message containing the user tag and the integer() or string() parameters as the first fields of respective type. integer() parameters should be put before any string() parameters. I.e. p(1,&quot;Hello&quot;) is ok, as is p(1,1) and p(&quot;Hello&quot;,&quot;Again&quot;) , but not p(&quot;Hello&quot;,1) .","ref":"dyntrace.html#p/2","title":"dyntrace.p/2","type":"function"},{"doc":"Calling this function will trigger the &quot;user&quot; trace probe user_trace_i4s4 in the dyntrace NIF module, sending a trace message containing the user tag and the integer() or string() parameters as the first fields of respective type. integer() parameters should be put before any string() parameters, as in p/2 .","ref":"dyntrace.html#p/3","title":"dyntrace.p/3","type":"function"},{"doc":"Calling this function will trigger the &quot;user&quot; trace probe user_trace_i4s4 in the dyntrace NIF module, sending a trace message containing the user tag and the integer() or string() parameters as the first fields of respective type. integer() parameters should be put before any string() parameters, as in p/2 .","ref":"dyntrace.html#p/4","title":"dyntrace.p/4","type":"function"},{"doc":"Calling this function will trigger the &quot;user&quot; trace probe user_trace_i4s4 in the dyntrace NIF module, sending a trace message containing the user tag and the integer() or string() parameters as the first fields of respective type. integer() parameters should be put before any string() parameters, as in p/2 . There can be no more than four parameters of any type (integer() or string()), so the first parameter has to be an integer() and the last a string().","ref":"dyntrace.html#p/5","title":"dyntrace.p/5","type":"function"},{"doc":"Calling this function will trigger the &quot;user&quot; trace probe user_trace_i4s4 in the dyntrace NIF module, sending a trace message containing the user tag and the integer() or string() parameters as the first fields of respective type. integer() parameters should be put before any string() parameters, as in p/2 . There can be no more than four parameters of any type (integer() or string()), so the first two parameters has to be integer()'s and the last two string()'s.","ref":"dyntrace.html#p/6","title":"dyntrace.p/6","type":"function"},{"doc":"Calling this function will trigger the &quot;user&quot; trace probe user_trace_i4s4 in the dyntrace NIF module, sending a trace message containing the user tag and the integer() or string() parameters as the first fields of respective type. integer() parameters should be put before any string() parameters, as in p/2 . There can be no more than four parameters of any type (integer() or string()), so the first three parameters has to be integer()'s and the last three string()'s.","ref":"dyntrace.html#p/7","title":"dyntrace.p/7","type":"function"},{"doc":"Calling this function will trigger the &quot;user&quot; trace probe user_trace_i4s4 in the dyntrace NIF module, sending a trace message containing all the integer()'s and string()'s provided, as well as any user tag set in the current process.","ref":"dyntrace.html#p/8","title":"dyntrace.p/8","type":"function"},{"doc":"Item = iodata() This function sets the user tag of the current process. The user tag is a binary(), but can be specified as any iodata(), which is automatically converted to a binary by this function. The user tag is provided to the user probes triggered by calls top dyntrace:p/{1,2,3,4,5,6,7,8} as well as probes in the efile_driver. In the future, user tags might be added to more probes. The old user tag (if any) is returned, or undefined if no user tag was present or dynamic tracing is not enabled.","ref":"dyntrace.html#put_tag/1","title":"dyntrace.put_tag/1","type":"function"},{"doc":"TagData = opaque data returned by spread_tag/1 Restores the previous state of user tags and their spreading as it was before a call to spread_tag/1 . Note that the restoring is not limited to the same process, one can utilize this to turn off spreding in one process and restore it in a newly created, the one that actually is going to send messages: f ( ) -&gt; TagData = dyntrace : spread_tag ( false ) , spawn ( fun ( ) -&gt; dyntrace : restore_tag ( TagData ) , do_something ( ) end ) , do_something_else ( ) , dyntrace : restore_tag ( TagData ) . Correctly handling user tags and their spreading might take some effort, as Erlang programs tend to send and receive messages so that sometimes the user tag gets lost due to various things, like double receives or communication with a port (ports do not handle user tags, in the same way as they do not handle regular sequential trace tokens).","ref":"dyntrace.html#restore_tag/1","title":"dyntrace.restore_tag/1","type":"function"},{"doc":"TagData = opaque data that can be used as parameter to restore_tag/1 This function controls if user tags are to be spread to other processes with the next message. Spreading of user tags work like spreading of sequential trace tokens, so that a received user tag will be active in the process until the next message arrives (if that message does not also contain the user tag. This functionality is used when a client process communicates with a file i/o-server to spread the user tag to the I/O-server and then down to the efile_drv driver. By using spread_tag/1 and restore_tag/1 , one can enable or disable spreading of user tags to other processes and then restore the previous state of the user tag. The TagData returned from this call contains all previous information so the state (including any previously spread user tags) will be completely restored by a later call to restore_tag/1 . The file module already spread's tags, so there is noo need to manually call these function to get user tags spread to the efile driver through that module. The most use of this function would be if one for example uses the io module to communicate with an I/O-server for a regular file, like in the following example: f ( ) -&gt; { ok , F } = file : open ( &quot;test.tst&quot; , [ write ] ) , Saved = dyntrace : spread_tag ( true ) , io : format ( F , &quot;Hello world!&quot; , [ ] ) , dyntrace : restore_tag ( Saved ) , file : close ( F ) . In this example, any user tag set in the calling process will be spread to the I/O-server when the io:format call is done.","ref":"dyntrace.html#spread_tag/1","title":"dyntrace.spread_tag/1","type":"function"},{"doc":"erts_alloc_config is currently an experimental tool and might be subject to backward incompatible changes. erts_alloc(3) is an Erlang Run-Time System internal memory allocator library. erts_alloc_config is intended to be used to aid creation of an erts_alloc(3) configuration that is suitable for a limited number of runtime scenarios. The configuration that erts_alloc_config produce is intended as a suggestion, and may need to be adjusted manually. The configuration is created based on information about a number of runtime scenarios. It is obviously impossible to foresee every runtime scenario that can occur. The important scenarios are those that cause maximum or minimum load on specific memory allocators. Load in this context is total size of memory blocks allocated. The current implementation of erts_alloc_config concentrate on configuration of multi-block carriers. Information gathered when a runtime scenario is saved is mainly current and maximum use of multi-block carriers. If a parameter that change the use of multi-block carriers is changed, a previously generated configuration is invalid and erts_alloc_config needs to be run again. It is mainly the single block carrier threshold that effects the use of multi-block carriers, but other single-block carrier parameters might as well. If another value of a single block carrier parameter than the default is desired, use the desired value when running erts_alloc_config . A configuration is created in the following way: Pass the +Mea config command-line flag to the Erlang runtime system you are going to use for creation of the allocator configuration. It will disable features that prevent erts_alloc_config from doing its job. Note, you should not use this flag when using the created configuration. Also note that it is important that you use the same amount of schedulers when creating the configuration as you are going the use on the system using the configuration. Run your applications with different scenarios (the more the better) and save information about each scenario by calling save_scenario/0 . It may be hard to know when the applications are at an (for erts_alloc_config ) important runtime scenario. A good approach may therefore be to call save_scenario/0 repeatedly, e.g. once every tenth second. Note that it is important that your applications reach the runtime scenarios that are important for erts_alloc_config when you are saving scenarios; otherwise, the configuration may perform bad. When you have covered all scenarios, call make_config/1 in order to create a configuration. The configuration is written to a file that you have chosen. This configuration file can later be read by an Erlang runtime-system at startup. Pass the command line argument -args_file FileName to the erl(1) command. The configuration produced by erts_alloc_config may need to be manually adjusted as already stated. Do not modify the file produced by erts_alloc_config ; instead, put your modifications in another file and load this file after the file produced by erts_alloc_config . That is, put the -args_file FileName argument that reads your modification file later on the command-line than the -args_file FileName argument that reads the configuration file produced by erts_alloc_config . If a memory allocation parameter appear multiple times, the last version of will be used, i.e., you can override parameters in the configuration file produced by erts_alloc_config . Doing it this way simplifies things when you want to rerun erts_alloc_config . The configuration created by erts_alloc_config may perform bad, ever horrible, for runtime scenarios that are very different from the ones saved when creating the configuration. You are, therefore, advised to rerun erts_alloc_config if the applications run when the configuration was made are changed, or if the load on the applications have changed since the configuration was made. You are also advised to rerun erts_alloc_config if the Erlang runtime system used is changed. erts_alloc_config saves information about runtime scenarios and performs computations in a server that is automatically started. The server register itself under the name '__erts_alloc_config__' . See Also erts_alloc(3), erl(1), io(3)","ref":"erts_alloc_config.html","title":"erts_alloc_config","type":"module"},{"doc":"Error = term() This is the same as calling make_config(group_leader()) .","ref":"erts_alloc_config.html#make_config/0","title":"erts_alloc_config.make_config/0","type":"function"},{"doc":"FileNameOrIODev = string() | io_device() Error = term() make_config/1 uses the information previously saved by save_scenario/0 in order to produce an erts_alloc configuration. At least one scenario have had to be saved. All scenarios previously saved will be used when creating the configuration. If FileNameOrIODev is a string() , make_config/1 will use FileNameOrIODev as a filename. A file named FileNameOrIODev is created and the configuration will be written to that file. If FileNameOrIODev is an io_device() (see the documentation of the module io ), the configuration will be written to the io device.","ref":"erts_alloc_config.html#make_config/1","title":"erts_alloc_config.make_config/1","type":"function"},{"doc":"Error = term() save_scenario/0 saves information about the current runtime scenario. This information will later be used when make_config/0 , or make_config/1 is called. The first time save_scenario/0 is called a server will be started. This server will save runtime scenarios. All saved scenarios can be removed by calling stop/0 .","ref":"erts_alloc_config.html#save_scenario/0","title":"erts_alloc_config.save_scenario/0","type":"function"},{"doc":"Error = term() Stops the server that saves runtime scenarios.","ref":"erts_alloc_config.html#stop/0","title":"erts_alloc_config.stop/0","type":"function"},{"doc":"This module implements some convenience functions for analyzing microstate accounting data. For details about how to use the basic api and what the different states represent see erlang:statistics(microstate_accounting) . Basic Scenario 1 &gt; msacc : start ( 1000 ) . ok 2 &gt; msacc : print ( ) . Average thread real - time : 1000513 us Accumulated system run - time : 2213 us Average scheduler run - time : 1076 us Thread aux check_io emulator gc other port sleep Stats per thread : async ( 0 ) 0.00 % 0.00% 0.00% 0.00% 0.00% 0.00% 100.00% async ( 1 ) 0.00 % 0.00% 0.00% 0.00% 0.00% 0.00% 100.00% aux ( 1 ) 0.00 % 0.00% 0.00% 0.00% 0.00% 0.00% 99.99% scheduler ( 1 ) 0.00 % 0.03% 0.13% 0.00% 0.01% 0.00% 99.82% scheduler ( 2 ) 0.00 % 0.00% 0.00% 0.00% 0.03% 0.00% 99.97% Stats per type : async 0.00 % 0.00% 0.00% 0.00% 0.00% 0.00% 100.00% aux 0.00 % 0.00% 0.00% 0.00% 0.00% 0.00% 99.99% scheduler 0.00 % 0.02% 0.06% 0.00% 0.02% 0.00% 99.89% ok This first command enables microstate accounting for 1000 milliseconds. See start/0 , stop/0 , reset/0 and start/1 for more details. The second command prints the statistics gathered during that time. First three general statistics are printed. Average real-time The average time spent collecting data in the threads. This should be close to the time which data was collected. System run-time The total run-time of all threads in the system. This is what you get if you call msacc:stats(total_runtime,Stats). Average scheduler run-time The average run-time for the schedulers. This is the average amount of time the schedulers did not sleep. Then one column per state is printed with a the percentage of time this thread spent in the state out of it's own real-time. After the thread specific time, the accumulated time for each type of thread is printed in a similar format. Since we have the average real-time and the percentage spent in each state we can easily calculate the time spent in each state by multiplying Average thread real-time with Thread state % , i.e. to get the time Scheduler 1 spent in the emulator state we do 1000513us * 0.13% = 1300us .","ref":"msacc.html","title":"msacc","type":"module"},{"doc":"This function checks whether microstate accounting is available or not.","ref":"msacc.html#available/0","title":"msacc.available/0","type":"function"},{"doc":"Read a file dump produced by to_file(Filename) .","ref":"msacc.html#from_file/1","title":"msacc.from_file/1","type":"function"},{"doc":"Prints the current microstate accounting to standard out. Same as msacc:print(msacc:stats(),\#{}).","ref":"msacc.html#print/0","title":"msacc.print/0","type":"function"},{"doc":"Print the given microstate statistics values to stdout. Same as msacc:print(DataOrStats,\#{}).","ref":"msacc.html#print/1","title":"msacc.print/1","type":"function"},{"doc":"Print the given microstate statistics values to standard out. With many states this can be quite verbose. See the top of this reference manual for a brief description of what the fields mean. It is possible to print more specific types of statistics by first manipulating the DataOrStats using stats/2 . For instance if you want to print the percentage of run-time for each thread you can do: msacc : print ( msacc : stats ( runtime , msacc : stats ( ) ) ) . If you want to only print run-time per thread type you can do: msacc : print ( msacc : stats ( type , msacc : stats ( runtime , msacc : stats ( ) ) ) ) . Options system Print percentage of time spent in each state out of system time as well as thread time. Default: false.","ref":"msacc.html#print/2","title":"msacc.print/2","type":"function"},{"doc":"Print the given microstate statistics values to the given file or device. The other arguments behave the same way as for print/2 .","ref":"msacc.html#print/3","title":"msacc.print/3","type":"function"},{"doc":"Reset microstate accounting counters. Returns whether is was enabled or disabled.","ref":"msacc.html#reset/0","title":"msacc.reset/0","type":"function"},{"doc":"Start microstate accounting. Returns whether it was previously enabled or disabled.","ref":"msacc.html#start/0","title":"msacc.start/0","type":"function"},{"doc":"Resets all counters and then starts microstate accounting for the given milliseconds.","ref":"msacc.html#start/1","title":"msacc.start/1","type":"function"},{"doc":"Returns a runtime system independent version of the microstate statistics data presented by erlang:statistics(microstate_accounting) . All counters have been normalized to be in microsecond resolution.","ref":"msacc.html#stats/0","title":"msacc.stats/0","type":"function"},{"doc":"Returns the system time for the given microstate statistics values. System time is the accumulated time of all threads. realtime Returns all time recorded for all threads. runtime Returns all time spent doing work for all threads, i.e. all time not spent in the sleep state.","ref":"msacc.html#stats/2","title":"msacc.stats/2","type":"function"},{"doc":"Returns fractions of real-time or run-time spent in the various threads from the given microstate statistics values.","ref":"msacc.html#stats/2","title":"msacc.stats/2","type":"function"},{"doc":"Returns a list of microstate statistics values where the values for all threads of the same type has been merged.","ref":"msacc.html#stats/2","title":"msacc.stats/2","type":"function"},{"doc":"Stop microstate accounting. Returns whether is was previously enabled or disabled.","ref":"msacc.html#stop/0","title":"msacc.stop/0","type":"function"},{"doc":"Dumps the current microstate statistics counters to a file that can be parsed with file:consult/1 .","ref":"msacc.html#to_file/1","title":"msacc.to_file/1","type":"function"},{"doc":"","ref":"msacc.html#t:msacc_data/0","title":"msacc.msacc_data/0","type":"type"},{"doc":"A map containing the different microstate accounting states and the number of microseconds spent in it.","ref":"msacc.html#t:msacc_data_counters/0","title":"msacc.msacc_data_counters/0","type":"type"},{"doc":"","ref":"msacc.html#t:msacc_data_thread/0","title":"msacc.msacc_data_thread/0","type":"type"},{"doc":"","ref":"msacc.html#t:msacc_id/0","title":"msacc.msacc_id/0","type":"type"},{"doc":"The different options that can be given to print/2 .","ref":"msacc.html#t:msacc_print_options/0","title":"msacc.msacc_print_options/0","type":"type"},{"doc":"The different states that a thread can be in. See erlang:statistics(microstate_accounting) for details.","ref":"msacc.html#t:msacc_state/0","title":"msacc.msacc_state/0","type":"type"},{"doc":"","ref":"msacc.html#t:msacc_stats/0","title":"msacc.msacc_stats/0","type":"type"},{"doc":"A map containing the different microstate accounting states. Each value in the map contains another map with the percentage of time that this thread has spent in the specific state. Both the percentage of system time and the time for that specific thread is part of the map.","ref":"msacc.html#t:msacc_stats_counters/0","title":"msacc.msacc_stats_counters/0","type":"type"},{"doc":"A map containing information about a specific thread. The percentages in the map can be either run-time or real-time depending on if runtime or realtime was requested from stats/2 . system is the percentage of total system time for this specific thread.","ref":"msacc.html#t:msacc_stats_thread/0","title":"msacc.msacc_stats_thread/0","type":"type"},{"doc":"","ref":"msacc.html#t:msacc_type/0","title":"msacc.msacc_type/0","type":"type"},{"doc":"This module contains utility functions for easier measurement and calculation of scheduler utilization, otherwise obtained from calling the more primitive statistics(scheduler_wall_time) . The simplest usage is to call scheduler:utilization(Seconds) .","ref":"scheduler.html","title":"scheduler","type":"module"},{"doc":"Return a scheduler utilization sample for normal and dirty-cpu schedulers.","ref":"scheduler.html#sample/0","title":"scheduler.sample/0","type":"function"},{"doc":"Return a scheduler utilization sample for all schedulers, including dirty-io schedulers.","ref":"scheduler.html#sample_all/0","title":"scheduler.sample_all/0","type":"function"},{"doc":"Measure utilization for normal and dirty-cpu schedulers during Seconds seconds, and then return the result.","ref":"scheduler.html#utilization/1","title":"scheduler.utilization/1","type":"function"},{"doc":"Calculate scheduler utilizations for the time interval from when Sample was taken and &quot;now&quot;. The same as calling scheduler:utilization(Sample, scheduler:sample_all()) . Scheduler utilization is measured as an average value over a time interval, calculated as the difference between two samples. To get good useful utilization values at least a couple of seconds should have passed between the two samples. For this reason, you should not do scheduler : utilization ( scheduler : sample ( ) ) . % DO NOT DO THIS! The above example takes two samples in rapid succession and calculates the scheduler utilization between them. The resulting values will probably be more misleading than informative. Instead use scheduler:utilization(Seconds) or let some time pass between Sample=scheduler:sample() and scheduler:utilization(Sample) .","ref":"scheduler.html#utilization/1","title":"scheduler.utilization/1","type":"function"},{"doc":"Calculates scheduler utilizations for the time interval between the two samples obtained from calling sample/0 or sample_all/0 .","ref":"scheduler.html#utilization/2","title":"scheduler.utilization/2","type":"function"},{"doc":"","ref":"scheduler.html#t:sched_id/0","title":"scheduler.sched_id/0","type":"type"},{"doc":"","ref":"scheduler.html#t:sched_sample/0","title":"scheduler.sched_sample/0","type":"opaque"},{"doc":"","ref":"scheduler.html#t:sched_type/0","title":"scheduler.sched_type/0","type":"type"},{"doc":"A list of tuples containing results for individual schedulers as well as aggregated averages. Util is the scheduler utilization as a floating point value between 0.0 and 1.0. Percent is the same utilization as a more human readable string expressed in percent. {normal, SchedulerId, Util, Percent} Scheduler utilization of a normal scheduler with number SchedulerId . Schedulers that are not online will also be included. Online schedulers have the lowest SchedulerId . {cpu, SchedulerId, Util, Percent} Scheduler utilization of a dirty-cpu scheduler with number SchedulerId . {io, SchedulerId, Util, Percent} Scheduler utilization of a dirty-io scheduler with number SchedulerId . This tuple will only exist if both samples were taken with sample_all/0 . {total, Util, Percent} Total utilization of all normal and dirty-cpu schedulers. {weighted, Util, Percent} Total utilization of all normal and dirty-cpu schedulers, weighted against maximum amount of available CPU time.","ref":"scheduler.html#t:sched_util_result/0","title":"scheduler.sched_util_result/0","type":"type"},{"doc":"","ref":"system_information.html","title":"system_information","type":"module"},{"doc":"Performs a sanity check on the system. If no issues were found, ok is returned. If issues were found, {failed, Failures} is returned. All failures found will be part of the Failures list. Currently defined Failure elements in the Failures list: InvalidAppFile An application has an invalid .app file. The second element identifies the application which has the invalid .app file. InvalidApplicationVersion An application has an invalid application version. The second element identifies the application version that is invalid. MissingRuntimeDependencies An application is missing runtime dependencies. The second element identifies the application (with version) that has missing dependencies. The third element contains the missing dependencies. Note that this check use application versions that are loaded, or will be loaded when used. You might have application versions that satisfies all dependencies installed in the system, but if those are not loaded this check will fail. The system will of course also fail when used like this. This may happen when you have multiple branched versions of the same application installed in the system, but you do not use a boot script identifing the correct application version. Currently the sanity check is limited to verifying runtime dependencies found in the .app files of all applications. More checks will be introduced in the future. This implies that the return type will change in the future. An ok return value only means that sanity_check/0 did not find any issues, not that no issues exist.","ref":"system_information.html#sanity_check/0","title":"system_information.sanity_check/0","type":"function"},{"doc":"Writes miscellaneous system information to file. This information will typically be requested by the Erlang/OTP team at Ericsson AB when reporting an issue.","ref":"system_information.html#to_file/1","title":"system_information.to_file/1","type":"function"}]